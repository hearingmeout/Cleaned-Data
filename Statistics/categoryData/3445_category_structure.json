{"above_fold":[{"id":22728,"internal_name":"2019-AP-Statistics-Framework-Unit-and-Topic","label":"Unit and Topic","description":"Unit and Topic","tags":[{"id":356622,"external_key":"19.apst.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2","label":"Unit and Topic","description":"Unit and Topic","tags":[{"id":356623,"external_key":"19.apst.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0","label":"1","description":"1: Exploring One-Variable Data","tags":[{"id":356624,"external_key":"19.apst.2.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.0","label":"1.1","description":"1.1: Introducing Statistics - What Can We Learn from Data?","tags":[]},{"id":356625,"external_key":"19.apst.2.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.1","label":"1.2","description":"1.2: The Language of Variation - Variables","tags":[]},{"id":356626,"external_key":"19.apst.2.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.2","label":"1.3","description":"1.3: Representing a Categorical Variable with Tables","tags":[]},{"id":356627,"external_key":"19.apst.2.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.3","label":"1.4","description":"1.4: Representing a Categorical Variable with Graphs","tags":[]},{"id":356628,"external_key":"19.apst.2.0.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.4","label":"1.5","description":"1.5: Representing a Quantitative Variable with Graphs","tags":[]},{"id":356629,"external_key":"19.apst.2.0.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.5","label":"1.6","description":"1.6: Describing the Distribution of a Quantitative Variable","tags":[]},{"id":356630,"external_key":"19.apst.2.0.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.6","label":"1.7","description":"1.7: Summary Statistics for a Quantitative Variable","tags":[]},{"id":356631,"external_key":"19.apst.2.0.7","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.7","label":"1.8","description":"1.8: Graphical Representations of Summary Statistics","tags":[]},{"id":356632,"external_key":"19.apst.2.0.8","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.8","label":"1.9","description":"1.9: Comparing Distributions of a Quantitative Variable","tags":[]},{"id":356633,"external_key":"19.apst.2.0.9","internal_name":"2019-AP-Statistics-Framework-19.apst.2.0.9","label":"1.10","description":"1.10: The Normal Distribution","tags":[]}]},{"id":356634,"external_key":"19.apst.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1","label":"2","description":"2: Exploring Two-Variable Data","tags":[{"id":356635,"external_key":"19.apst.2.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.0","label":"2.1","description":"2.1: Introducing Statistics - Are Variables Related?","tags":[]},{"id":356636,"external_key":"19.apst.2.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.1","label":"2.2","description":"2.2: Representing Two Categorical Variables","tags":[]},{"id":356637,"external_key":"19.apst.2.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.2","label":"2.3","description":"2.3: Statistics for Two Categorical Variables","tags":[]},{"id":356638,"external_key":"19.apst.2.1.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.3","label":"2.4","description":"2.4: Representing the Relationship Between Two Quantitative Variables","tags":[]},{"id":356639,"external_key":"19.apst.2.1.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.4","label":"2.5","description":"2.5: Correlation","tags":[]},{"id":356640,"external_key":"19.apst.2.1.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.5","label":"2.6","description":"2.6: Linear Regression Models","tags":[]},{"id":356641,"external_key":"19.apst.2.1.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.6","label":"2.7","description":"2.7: Residuals","tags":[]},{"id":356642,"external_key":"19.apst.2.1.7","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.7","label":"2.8","description":"2.8: Least Squares Regression","tags":[]},{"id":356643,"external_key":"19.apst.2.1.8","internal_name":"2019-AP-Statistics-Framework-19.apst.2.1.8","label":"2.9","description":"2.9: Analyzing Departures from Linearity","tags":[]}]},{"id":356644,"external_key":"19.apst.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.2","label":"3","description":"3: Collecting Data","tags":[{"id":356645,"external_key":"19.apst.2.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.2.0","label":"3.1","description":"3.1: Introducing Statistics - Do the Data We Collected Tell the Truth?","tags":[]},{"id":356646,"external_key":"19.apst.2.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.2.1","label":"3.2","description":"3.2: Introduction to Planning a Study","tags":[]},{"id":356647,"external_key":"19.apst.2.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.2.2","label":"3.3","description":"3.3: Random Sampling and Data Collection","tags":[]},{"id":356648,"external_key":"19.apst.2.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.2.3","label":"3.4","description":"3.4: Potential Problems with Sampling","tags":[]},{"id":356649,"external_key":"19.apst.2.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.2.4","label":"3.5","description":"3.5: Introduction to Experimental Design","tags":[]},{"id":356650,"external_key":"19.apst.2.2.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.2.5","label":"3.6","description":"3.6: Selecting an Experimental Design","tags":[]},{"id":356651,"external_key":"19.apst.2.2.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.2.6","label":"3.7","description":"3.7: Inference and Experiments","tags":[]}]},{"id":356652,"external_key":"19.apst.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3","label":"4","description":"4: Probability, Random Variables, and Probability Distributions","tags":[{"id":356653,"external_key":"19.apst.2.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.0","label":"4.1","description":"4.1: Introducing Statistics - Random and Non-Random Patterns?","tags":[]},{"id":356654,"external_key":"19.apst.2.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.1","label":"4.2","description":"4.2: Estimating Probabilities Using Simulation","tags":[]},{"id":356655,"external_key":"19.apst.2.3.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.2","label":"4.3","description":"4.3: Introduction to Probability","tags":[]},{"id":356656,"external_key":"19.apst.2.3.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.3","label":"4.4","description":"4.4: Mutually Exclusive Events","tags":[]},{"id":356657,"external_key":"19.apst.2.3.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.4","label":"4.5","description":"4.5: Conditional Probability","tags":[]},{"id":356658,"external_key":"19.apst.2.3.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.5","label":"4.6","description":"4.6: Independent Events and Unions of Events","tags":[]},{"id":356659,"external_key":"19.apst.2.3.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.6","label":"4.7","description":"4.7: Introduction to Random Variables and Probability Distributions","tags":[]},{"id":356660,"external_key":"19.apst.2.3.7","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.7","label":"4.8","description":"4.8: Mean and Standard Deviation of Random Variables","tags":[]},{"id":356661,"external_key":"19.apst.2.3.8","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.8","label":"4.9","description":"4.9: Combining Random Variables","tags":[]},{"id":356662,"external_key":"19.apst.2.3.9","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.9","label":"4.10","description":"4.10: Introduction to the Binomial Distribution","tags":[]},{"id":356663,"external_key":"19.apst.2.3.10","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.10","label":"4.11","description":"4.11: Parameters for a Binomial Distribution","tags":[]},{"id":356664,"external_key":"19.apst.2.3.11","internal_name":"2019-AP-Statistics-Framework-19.apst.2.3.11","label":"4.12","description":"4.12: The Geometric Distribution","tags":[]}]},{"id":356665,"external_key":"19.apst.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4","label":"5","description":"5: Sampling Distributions","tags":[{"id":356666,"external_key":"19.apst.2.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4.0","label":"5.1","description":"5.1: Introducing Statistics - Why Is My Sample Not Like Yours?","tags":[]},{"id":356667,"external_key":"19.apst.2.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4.1","label":"5.2","description":"5.2: The Normal Distribution, Revisited","tags":[]},{"id":356668,"external_key":"19.apst.2.4.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4.2","label":"5.3","description":"5.3: The Central Limit Theorem","tags":[]},{"id":356669,"external_key":"19.apst.2.4.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4.3","label":"5.4","description":"5.4: Biased and Unbiased Point Estimates","tags":[]},{"id":356670,"external_key":"19.apst.2.4.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4.4","label":"5.5","description":"5.5: Sampling Distributions for Sample Proportions","tags":[]},{"id":356671,"external_key":"19.apst.2.4.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4.5","label":"5.6","description":"5.6: Sampling Distributions for Differences in Sample Proportions","tags":[]},{"id":356672,"external_key":"19.apst.2.4.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4.6","label":"5.7","description":"5.7: Sampling Distributions for Sample Means","tags":[]},{"id":356673,"external_key":"19.apst.2.4.7","internal_name":"2019-AP-Statistics-Framework-19.apst.2.4.7","label":"5.8","description":"5.8: Sampling Distributions for Differences in Sample Means","tags":[]}]},{"id":356674,"external_key":"19.apst.2.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5","label":"6","description":"6: Inference for Categorical Data-Proportions","tags":[{"id":356675,"external_key":"19.apst.2.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.0","label":"6.1","description":"6.1: Introducing Statistics - Why Be Normal?","tags":[]},{"id":356676,"external_key":"19.apst.2.5.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.1","label":"6.2","description":"6.2: Constructing a Confidence Interval for a Population Proportion","tags":[]},{"id":356677,"external_key":"19.apst.2.5.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.2","label":"6.3","description":"6.3: Justifying a Claim Based on a Confidence Interval for a Population Proportion","tags":[]},{"id":356678,"external_key":"19.apst.2.5.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.3","label":"6.4","description":"6.4: Setting Up a Test for a Population Proportion","tags":[]},{"id":356679,"external_key":"19.apst.2.5.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.4","label":"6.5","description":"6.5: Interpreting P-Values","tags":[]},{"id":356680,"external_key":"19.apst.2.5.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.5","label":"6.6","description":"6.6: Concluding a Test for a Population Proportion","tags":[]},{"id":356681,"external_key":"19.apst.2.5.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.6","label":"6.7","description":"6.7: Potential Errors When Performing Tests","tags":[]},{"id":356682,"external_key":"19.apst.2.5.7","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.7","label":"6.8","description":"6.8: Confidence Intervals for the Difference of Two Proportions","tags":[]},{"id":356683,"external_key":"19.apst.2.5.8","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.8","label":"6.9","description":"6.9: Justifying a Claim Based on a Confidence Interval for a Difference Between Population Proportions","tags":[]},{"id":356684,"external_key":"19.apst.2.5.9","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.9","label":"6.10","description":"6.10: Setting Up a Test for the Difference of Two Population Proportions","tags":[]},{"id":356685,"external_key":"19.apst.2.5.10","internal_name":"2019-AP-Statistics-Framework-19.apst.2.5.10","label":"6.11","description":"6.11: Carrying Out a Test for the Difference of Two Population Proportions","tags":[]}]},{"id":356686,"external_key":"19.apst.2.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6","label":"7","description":"7: Inference for Quantitative Data-Means","tags":[{"id":356687,"external_key":"19.apst.2.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.0","label":"7.1","description":"7.1: Introducing Statistics - Should I Worry About Error?","tags":[]},{"id":356688,"external_key":"19.apst.2.6.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.1","label":"7.2","description":"7.2: Constructing a Confidence Interval for a Population Mean","tags":[]},{"id":356689,"external_key":"19.apst.2.6.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.2","label":"7.3","description":"7.3: Justifying a Claim About a Population Mean Based on a Confidence Interval","tags":[]},{"id":356690,"external_key":"19.apst.2.6.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.3","label":"7.4","description":"7.4: Setting Up a Test for a Population Mean","tags":[]},{"id":356691,"external_key":"19.apst.2.6.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.4","label":"7.5","description":"7.5: Carrying Out a Test for a Population Mean","tags":[]},{"id":356692,"external_key":"19.apst.2.6.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.5","label":"7.6","description":"7.6: Confidence Intervals for the Difference of Two Means","tags":[]},{"id":356693,"external_key":"19.apst.2.6.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.6","label":"7.7","description":"7.7: Justifying a Claim About the Difference of Two Means Based on a Confidence Interval","tags":[]},{"id":356694,"external_key":"19.apst.2.6.7","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.7","label":"7.8","description":"7.8: Setting Up a Test for the Difference of Two Population Means","tags":[]},{"id":356695,"external_key":"19.apst.2.6.8","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.8","label":"7.9","description":"7.9: Carrying Out a Test for the Difference of Two Population Means","tags":[]},{"id":356696,"external_key":"19.apst.2.6.9","internal_name":"2019-AP-Statistics-Framework-19.apst.2.6.9","label":"7.10","description":"7.10: Skills Focus - Selecting, Implementing, and Communicating Inference Procedures","tags":[]}]},{"id":356697,"external_key":"19.apst.2.7","internal_name":"2019-AP-Statistics-Framework-19.apst.2.7","label":"8","description":"8: Inference for Categorical Data-Chi-Square","tags":[{"id":356698,"external_key":"19.apst.2.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.7.0","label":"8.1","description":"8.1: Introducing Statistics - Are My Results Unexpected?","tags":[]},{"id":356699,"external_key":"19.apst.2.7.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.7.1","label":"8.2","description":"8.2: Setting up a Chi-Square Goodness of Fit Test","tags":[]},{"id":356700,"external_key":"19.apst.2.7.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.7.2","label":"8.3","description":"8.3: Carrying out a Chi-Square Goodness of Fit Test","tags":[]},{"id":356701,"external_key":"19.apst.2.7.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.7.3","label":"8.4","description":"8.4: Expected Counts in Two-Way Tables","tags":[]},{"id":356702,"external_key":"19.apst.2.7.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.7.4","label":"8.5","description":"8.5: Setting Up a Chi-Square Test for Homogeneity or Independence","tags":[]},{"id":356703,"external_key":"19.apst.2.7.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.7.5","label":"8.6","description":"8.6: Carrying Out a Chi-Square Test for Homogeneity or Independence","tags":[]},{"id":356704,"external_key":"19.apst.2.7.6","internal_name":"2019-AP-Statistics-Framework-19.apst.2.7.6","label":"8.7","description":"8.7: Skills Focus - Selecting an Appropriate Inference Procedure for Categorical Data","tags":[]}]},{"id":356705,"external_key":"19.apst.2.8","internal_name":"2019-AP-Statistics-Framework-19.apst.2.8","label":"9","description":"9: Inference for Quantitative Data-Slopes","tags":[{"id":356706,"external_key":"19.apst.2.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.2.8.0","label":"9.1","description":"9.1: Introducing Statistics - Do Those Points Align?","tags":[]},{"id":356707,"external_key":"19.apst.2.8.1","internal_name":"2019-AP-Statistics-Framework-19.apst.2.8.1","label":"9.2","description":"9.2: Confidence Intervals for the Slope of a Regression Model","tags":[]},{"id":356708,"external_key":"19.apst.2.8.2","internal_name":"2019-AP-Statistics-Framework-19.apst.2.8.2","label":"9.3","description":"9.3: Justifying a Claim About the Slope of a Regression Model Based on a Confidence Interval","tags":[]},{"id":356709,"external_key":"19.apst.2.8.3","internal_name":"2019-AP-Statistics-Framework-19.apst.2.8.3","label":"9.4","description":"9.4: Setting Up a Test for the Slope of a Regression Model","tags":[]},{"id":356710,"external_key":"19.apst.2.8.4","internal_name":"2019-AP-Statistics-Framework-19.apst.2.8.4","label":"9.5","description":"9.5: Carrying Out a Test for the Slope of a Regression Model","tags":[]},{"id":382229,"external_key":"19.apst.2.8.5","internal_name":"2019-AP-Statistics-Framework-19.apst.2.8.5","label":"9.6","description":"9.6: Skills Focus - Selecting an Appropriate Inference Procedure","tags":[]}]}]}]},{"id":22725,"internal_name":"2019-AP-Statistics-Framework-Skill-Category-and-Skill","label":"Skill Category and Skill","description":"Skill Category and Skill","tags":[{"id":356597,"external_key":"19.apst.1","internal_name":"2019-AP-Statistics-Framework-19.apst.1","label":"Skill Category and Skill","description":"Skill Category and Skill","tags":[{"id":356598,"external_key":"19.apst.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.1.0","label":"Skill Category 1","description":"Skill Category 1: Select methods for collecting and/or analyzing data for statistical inference.","tags":[{"id":356599,"external_key":"19.apst.1.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.1.0.0","label":"Skill 1.A","description":"Skill 1.A: Identify the question to be answered or problem to be solved.","tags":[]},{"id":356600,"external_key":"19.apst.1.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.1.0.1","label":"Skill 1.B","description":"Skill 1.B: Identify key and relevant information to answer a question or solve a problem.","tags":[]},{"id":356601,"external_key":"19.apst.1.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.1.0.2","label":"Skill 1.C","description":"Skill 1.C: Describe an appropriate method for gathering and representing data.","tags":[]},{"id":356602,"external_key":"19.apst.1.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.1.0.3","label":"Skill 1.D","description":"Skill 1.D: Identify an appropriate inference method for confidence intervals.","tags":[]},{"id":356603,"external_key":"19.apst.1.0.4","internal_name":"2019-AP-Statistics-Framework-19.apst.1.0.4","label":"Skill 1.E","description":"Skill 1.E: Identify an appropriate inference method for significance tests.","tags":[]},{"id":356604,"external_key":"19.apst.1.0.5","internal_name":"2019-AP-Statistics-Framework-19.apst.1.0.5","label":"Skill 1.F","description":"Skill 1.F: Identify null and alternative hypotheses.","tags":[]}]},{"id":356605,"external_key":"19.apst.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.1.1","label":"Skill Category 2","description":"Skill Category 2: Describe patterns, trends, associations, and relationships in data.","tags":[{"id":356606,"external_key":"19.apst.1.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.1.1.0","label":"Skill 2.A","description":"Skill 2.A: Describe data presented numerically or graphically.","tags":[]},{"id":356607,"external_key":"19.apst.1.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.1.1.1","label":"Skill 2.B","description":"Skill 2.B: Construct numerical or graphical representations of distributions.","tags":[]},{"id":356608,"external_key":"19.apst.1.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.1.1.2","label":"Skill 2.C","description":"Skill 2.C: Calculate summary statistics, relative positions of points within a distribution, correlation, and predicted response.","tags":[]},{"id":356609,"external_key":"19.apst.1.1.3","internal_name":"2019-AP-Statistics-Framework-19.apst.1.1.3","label":"Skill 2.D","description":"Skill 2.D: Compare distributions or relative positions of points within a distribution.","tags":[]}]},{"id":356610,"external_key":"19.apst.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.1.2","label":"Skill Category 3","description":"Skill Category 3: Explore random phenomena.","tags":[{"id":356611,"external_key":"19.apst.1.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.1.2.0","label":"Skill 3.A","description":"Skill 3.A: Determine relative frequencies, proportions, or probabilities using simulation or calculations.","tags":[]},{"id":356612,"external_key":"19.apst.1.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.1.2.1","label":"Skill 3.B","description":"Skill 3.B: Determine parameters for probability distributions.","tags":[]},{"id":356613,"external_key":"19.apst.1.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.1.2.2","label":"Skill 3.C","description":"Skill 3.C: Describe probability distributions.","tags":[]},{"id":356614,"external_key":"19.apst.1.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.1.2.3","label":"Skill 3.D","description":"Skill 3.D: Construct a confidence interval, provided conditions for inference are met.","tags":[]},{"id":356615,"external_key":"19.apst.1.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.1.2.4","label":"Skill 3.E","description":"Skill 3.E: Calculate a test statistic and find a p-value, provided conditions for inference are met.","tags":[]}]},{"id":356616,"external_key":"19.apst.1.3","internal_name":"2019-AP-Statistics-Framework-19.apst.1.3","label":"Skill Category 4","description":"Skill Category 4: Develop an explanation or justify a conclusion using evidence from data, definitions, or statistical inference.","tags":[{"id":356617,"external_key":"19.apst.1.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.1.3.0","label":"Skill 4.A","description":"Skill 4.A: Make an appropriate claim or draw an appropriate conclusion.","tags":[]},{"id":356618,"external_key":"19.apst.1.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.1.3.1","label":"Skill 4.B","description":"Skill 4.B: Interpret statistical calculations and findings to assign meaning or assess a claim.","tags":[]},{"id":356619,"external_key":"19.apst.1.3.2","internal_name":"2019-AP-Statistics-Framework-19.apst.1.3.2","label":"Skill 4.C","description":"Skill 4.C: Verify that inference procedures apply in a given situation.","tags":[]},{"id":356620,"external_key":"19.apst.1.3.3","internal_name":"2019-AP-Statistics-Framework-19.apst.1.3.3","label":"Skill 4.D","description":"Skill 4.D: Justify a claim based on a confidence interval.","tags":[]},{"id":356621,"external_key":"19.apst.1.3.4","internal_name":"2019-AP-Statistics-Framework-19.apst.1.3.4","label":"Skill 4.E","description":"Skill 4.E: Justify a claim using a decision based on significance tests.","tags":[]}]}]}]},{"id":22731,"internal_name":"2019-AP-Statistics-Framework-Assessment-Purpose-and-Source","label":"Assessment Purpose and Source","description":"Assessment Purpose and Source","tags":[{"id":356711,"external_key":"19.apst.3","internal_name":"2019-AP-Statistics-Framework-19.apst.3","label":"Assessment Purpose and Source","description":"Assessment Purpose and Source","tags":[{"id":356712,"external_key":"19.apst.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.3.0","label":"Formative","description":"Formative","tags":[{"id":356713,"external_key":"19.apst.3.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.3.0.0","label":"AP Topic Question","description":"AP Topic Question","tags":[]},{"id":356714,"external_key":"19.apst.3.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.3.0.1","label":"My Question","description":"My Question","tags":[]},{"id":413878,"external_key":"19.apst.3.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.3.0.1","label":"AP Progress Check","description":"AP Progress Check","tags":[]}]},{"id":356715,"external_key":"19.apst.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1","label":"Summative","description":"Summative","tags":[{"id":356716,"external_key":"19.apst.3.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1.0","label":"AP Course and Exam Description","description":"AP Course and Exam Description","tags":[]},{"id":356717,"external_key":"19.apst.3.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1.1","label":"AP Exam","description":"AP Exam","tags":[]},{"id":356718,"external_key":"19.apst.3.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1.2","label":"AP Practice Exam","description":"AP Practice Exam","tags":[{"id":375414,"external_key":"19.apst.3.1.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1.2.0","label":"2017 International Practice Exam","description":"2017 International Practice Exam","tags":[]},{"id":375415,"external_key":"19.apst.3.1.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1.2.1","label":"2018 International Practice Exam","description":"2018 International Practice Exam","tags":[]},{"id":375416,"external_key":"19.apst.3.1.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1.2.2","label":"2019 International Practice Exam","description":"2019 International Practice Exam","tags":[]},{"id":380353,"external_key":"19.apst.3.1.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1.2.3","label":"Previous Practice Question","description":"Previous Practice Question","tags":[]}]},{"id":356719,"external_key":"19.apst.3.1.3","internal_name":"2019-AP-Statistics-Framework-19.apst.3.1.3","label":"My Question","description":"My Question","tags":[]}]}]}]},{"id":22742,"internal_name":"2019-AP-Statistics-General-Exam-Alignment","label":"Exam Alignment","description":"Exam Alignment","tags":[{"id":356775,"external_key":null,"internal_name":"2019-AP-Statistics-General-Exam-Alignment-High","label":"High","description":"High","tags":[]},{"id":356778,"external_key":null,"internal_name":"2019-AP-Statistics-General-Exam-Alignment-Partial","label":"Partial","description":"Partial","tags":[]}]},{"id":22720,"internal_name":"2019-AP-Statistics-Framework-Big-Idea-and-Learning-Objective","label":"Big Idea and Learning Objective","description":"Big Idea and Learning Objective","tags":[{"id":356032,"external_key":"19.apst.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0","label":"Big Idea and Learning Objective","description":"Big Idea and Learning Objective","tags":[{"id":356033,"external_key":"19.apst.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0","label":"DAT","description":"DAT: Data-Based Predictions, Decisions, and Conclusions","tags":[{"id":356034,"external_key":"19.apst.0.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0","label":"DAT-1","description":"DAT-1: Regression models may allow us to predict responses to changes in an explanatory variable.","tags":[{"id":356035,"external_key":"19.apst.0.0.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.0","label":"DAT-1.A","description":"DAT-1.A: Describe the characteristics of a scatter plot.","tags":[{"id":356036,"external_key":"19.apst.0.0.0.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.0.0","label":"DAT-1.A.1","description":"DAT-1.A.1: A description of a scatter plot includes form, direction, strength, and unusual features.","tags":[]},{"id":356037,"external_key":"19.apst.0.0.0.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.0.1","label":"DAT-1.A.2","description":"DAT-1.A.2: The direction of the association shown in a scatterplot, if any, can be described as positive or negative.","tags":[]},{"id":356038,"external_key":"19.apst.0.0.0.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.0.2","label":"DAT-1.A.3","description":"DAT-1.A.3: A positive association means that as values of one variable increase, the values of the other variable tend to increase. A negative association means that as values of one variable increase, values of the other variable tend to decrease.","tags":[]},{"id":356039,"external_key":"19.apst.0.0.0.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.0.3","label":"DAT-1.A.4","description":"DAT-1.A.4: The form of the association shown in a scatterplot, if any, can be described as linear or non-linear to varying degrees.","tags":[]},{"id":356040,"external_key":"19.apst.0.0.0.0.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.0.4","label":"DAT-1.A.5","description":"DAT-1.A.5: The strength of the association is how closely the individual points follow a specific pattern, e.g. linear, and can be shown in a scatterplot. Strength can be described as strong, moderate, or weak.","tags":[]},{"id":356041,"external_key":"19.apst.0.0.0.0.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.0.5","label":"DAT-1.A.6","description":"DAT-1.A.6: Unusual features of a scatter plot include clusters of points or points with relatively large discrepancies between the value of the response variable and a predicted value for the response variable.","tags":[]}]},{"id":356042,"external_key":"19.apst.0.0.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.1","label":"DAT-1.B","description":"DAT-1.B: Determine the correlation for a linear relationship.","tags":[{"id":356043,"external_key":"19.apst.0.0.0.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.1.0","label":"DAT-1.B.1","description":"DAT-1.B.1: The correlation, r, gives the direction and quantifies the strength of the linear association between two quantitative variables.","tags":[]},{"id":356044,"external_key":"19.apst.0.0.0.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.1.1","label":"DAT-1.B.2","description":"DAT-1.B.2: The correlation coefficient can be calculated by- r = [1/(n - 1)][∑((x_i - x-bar)/s_x)((y_i - y-bar)/s_y)]. However, the most common way to determine r is by using technology.","tags":[]},{"id":356045,"external_key":"19.apst.0.0.0.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.1.2","label":"DAT-1.B.3","description":"DAT-1.B.3: A correlation coefficient close to 1 or -1 does not necessarily mean that a linear model is appropriate.","tags":[]}]},{"id":356046,"external_key":"19.apst.0.0.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.2","label":"DAT-1.C","description":"DAT-1.C: Interpret the correlation for a linear relationship.","tags":[{"id":356047,"external_key":"19.apst.0.0.0.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.2.0","label":"DAT-1.C.1","description":"DAT-1.C.1: The correlation, r, is unit-free, and always between -1 and 1, inclusive. A value of r = 0 indicates that there is no linear association. A value of r=1 or r=-1 indicates that there is a perfect linear association.","tags":[]},{"id":356048,"external_key":"19.apst.0.0.0.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.2.1","label":"DAT-1.C.2","description":"DAT-1.C.2: A perceived or real relationship between two variables does not mean that changes in one variable cause changes in the other. That is, correlation does not necessarily imply causation.","tags":[]}]},{"id":356049,"external_key":"19.apst.0.0.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.3","label":"DAT-1.D","description":"DAT-1.D: Calculate a predicted response value using a linear regression model.","tags":[{"id":356050,"external_key":"19.apst.0.0.0.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.3.0","label":"DAT-1.D.1","description":"DAT-1.D.1: A simple linear regression model is an equation that uses an explanatory variable, x, to predict the response variable, y.","tags":[]},{"id":356051,"external_key":"19.apst.0.0.0.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.3.1","label":"DAT-1.D.2","description":"DAT-1.D.2: The predicted response value, denoted by y-hat, is calculated as y-hat = a + bx, where a is the y-intercept and b is the slope of the regression line, and x is the value of the explanatory variable.","tags":[]},{"id":356052,"external_key":"19.apst.0.0.0.3.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.3.2","label":"DAT-1.D.3","description":"DAT-1.D.3: Extrapolation is predicting a response value using a value for the explanatory variable that is beyond the interval of x-values used to determine the regression line. The predicted value is less reliable as an estimate the further we extrapolate.","tags":[]}]},{"id":356053,"external_key":"19.apst.0.0.0.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.4","label":"DAT-1.E","description":"DAT-1.E: Represent differences between measured and predicted responses using residual plots.","tags":[{"id":356054,"external_key":"19.apst.0.0.0.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.4.0","label":"DAT-1.E.1","description":"DAT-1.E.1: The residual is the difference between the actual value and the predicted value; so residual = y - y-hat.","tags":[]},{"id":356055,"external_key":"19.apst.0.0.0.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.4.1","label":"DAT-1.E.2","description":"DAT-1.E.2: A residual plot is a plot of residuals versus explanatory variable values or predicted response values.","tags":[]}]},{"id":356056,"external_key":"19.apst.0.0.0.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.5","label":"DAT-1.F","description":"DAT-1.F: Describe the form of association of bivariate data using residual plots.","tags":[{"id":356057,"external_key":"19.apst.0.0.0.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.5.0","label":"DAT-1.F.1","description":"DAT-1.F.1: Apparent randomness in a residual plot for a linear model is evidence of a linear form to the association between the variables.","tags":[]},{"id":356058,"external_key":"19.apst.0.0.0.5.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.5.1","label":"DAT-1.F.2","description":"DAT-1.F.2: Residual plots can be used to investigate the appropriateness of a selected model.","tags":[]}]},{"id":356059,"external_key":"19.apst.0.0.0.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.6","label":"DAT-1.G","description":"DAT-1.G: Estimate parameters for the least-squares regression line model.","tags":[{"id":356060,"external_key":"19.apst.0.0.0.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.6.0","label":"DAT-1.G.1","description":"DAT-1.G.1: The least-squares regression line model minimizes the sum of the squares of the residuals and contains the point (x-bar, y-bar).","tags":[]},{"id":356061,"external_key":"19.apst.0.0.0.6.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.6.1","label":"DAT-1.G.2","description":"DAT-1.G.2: The slope, b, of the regression line can be calculated as b = r[(s_y)/(s_x)], where r is the correlation between x and y, s_y is the sample standard deviation of the response variable, y, and s_x is the sample standard deviation of the explanatory variable, x.","tags":[]},{"id":356062,"external_key":"19.apst.0.0.0.6.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.6.2","label":"DAT-1.G.3","description":"DAT-1.G.3: Sometimes, the y-intercept of the line does not have a logical interpretation in context.","tags":[]},{"id":356063,"external_key":"19.apst.0.0.0.6.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.6.3","label":"DAT-1.G.4","description":"DAT-1.G.4: In simple linear regression, r² is the square of the correlation, r. It is also called the coefficient of determination. r² is the proportion of variation in the response variable that is explained by the explanatory variable in the model.","tags":[]}]},{"id":356064,"external_key":"19.apst.0.0.0.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.7","label":"DAT-1.H","description":"DAT-1.H: Interpret coefficients for the least-squares regression line model.","tags":[{"id":356065,"external_key":"19.apst.0.0.0.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.7.0","label":"DAT-1.H.1","description":"DAT-1.H.1: The coefficients of the least-squares regression line model are the estimated slope and y-intercept.","tags":[]},{"id":356066,"external_key":"19.apst.0.0.0.7.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.7.1","label":"DAT-1.H.2","description":"DAT-1.H.2: The slope is the amount that the predicted y-value changes for every unit increase in x.","tags":[]},{"id":356067,"external_key":"19.apst.0.0.0.7.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.7.2","label":"DAT-1.H.3","description":"DAT-1.H.3: The y-intercept value is the predicted value of the response variable when the explanatory variable is equal to 0. The formula for the y-intercept, α, is α = y-bar - b · x-bar.","tags":[]}]},{"id":356068,"external_key":"19.apst.0.0.0.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.8","label":"DAT-1.I","description":"DAT-1.I: Identify influential points in regression.","tags":[{"id":356069,"external_key":"19.apst.0.0.0.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.8.0","label":"DAT-1.I.1","description":"DAT-1.I.1: An outlier in regression is a point that does not follow the general trend shown in the rest of the data and has a large residual when the least-squares regression line (LSRL) is calculated.","tags":[]},{"id":356070,"external_key":"19.apst.0.0.0.8.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.8.1","label":"DAT-1.I.2","description":"DAT-1.I.2: A high-leverage point in regression has a substantially larger or smaller x-value than the other observations have.","tags":[]},{"id":356071,"external_key":"19.apst.0.0.0.8.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.8.2","label":"DAT-1.I.3","description":"DAT-1.I.3: An influential point in regression is any point that, if removed, changes the relationship substantially. Examples include much different slope, y-intercept, and/or correlation. Outliers and high leverage points are often influential.","tags":[]}]},{"id":356072,"external_key":"19.apst.0.0.0.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.9","label":"DAT-1.J","description":"DAT-1.J: Calculate a predicted response using a least-squares regression line for a transformed data set.","tags":[{"id":356073,"external_key":"19.apst.0.0.0.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.9.0","label":"DAT-1.J.1","description":"DAT-1.J.1: Transformations of variables, such as evaluating the natural logarithm of each value of the response variable or squaring each value of the explanatory variable, can be used to create transformed data sets, which may be more linear in form than the untransformed data.","tags":[]},{"id":356074,"external_key":"19.apst.0.0.0.9.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.0.9.1","label":"DAT-1.J.2","description":"DAT-1.J.2: Increased randomness in residual plots after transformation of data and/or movement of r² to a value closer to 1 offers evidence that the least-squares regression line for the transformed data is a more appropriate model to use to predict responses to the explanatory variable than the regression line for the untransformed data.","tags":[]}]}]},{"id":356075,"external_key":"19.apst.0.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1","label":"DAT-2","description":"DAT-2: The way we collect data influences what we can and cannot say about a population.","tags":[{"id":356076,"external_key":"19.apst.0.0.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.0","label":"DAT-2.A","description":"DAT-2.A: Identify the type of a study.","tags":[{"id":356077,"external_key":"19.apst.0.0.1.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.0.0","label":"DAT-2.A.1","description":"DAT-2.A.1: A population consists of all items or subjects of interest.","tags":[]},{"id":356078,"external_key":"19.apst.0.0.1.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.0.1","label":"DAT-2.A.2","description":"DAT-2.A.2: A sample selected for study is a subset of the population.","tags":[]},{"id":356079,"external_key":"19.apst.0.0.1.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.0.2","label":"DAT-2.A.3","description":"DAT-2.A.3: In an observational study, treatments are not imposed. Investigators examine data for a sample of individuals (retrospective) or follow a sample of individuals into the future collecting data (prospective) in order to investigate a topic of interest about the population. A sample survey is a type of observational study that collects data from a sample in an attempt to learn about the population from which the sample was taken.","tags":[]},{"id":356080,"external_key":"19.apst.0.0.1.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.0.3","label":"DAT-2.A.4","description":"DAT-2.A.4: In an experiment, different conditions (treatments) are assigned to experimental units (participants or subjects).","tags":[]}]},{"id":356081,"external_key":"19.apst.0.0.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.1","label":"DAT-2.B","description":"DAT-2.B: Identify appropriate generalizations and determinations based on observational studies.","tags":[{"id":356082,"external_key":"19.apst.0.0.1.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.1.0","label":"DAT-2.B.1","description":"DAT-2.B.1: It is only appropriate to make generalizations about a population based on samples that are randomly selected or otherwise representative of that population.","tags":[]},{"id":356083,"external_key":"19.apst.0.0.1.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.1.1","label":"DAT-2.B.2","description":"DAT-2.B.2: A sample is only generalizable to the population from which the sample was selected.","tags":[]},{"id":356084,"external_key":"19.apst.0.0.1.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.1.2","label":"DAT-2.B.3","description":"DAT-2.B.3: It is not possible to determine causal relationships between variables using data collected in an observational study.","tags":[]}]},{"id":356085,"external_key":"19.apst.0.0.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.2","label":"DAT-2.C","description":"DAT-2.C: Identify a sampling method, given a description of a study.","tags":[{"id":356086,"external_key":"19.apst.0.0.1.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.2.0","label":"DAT-2.C.1","description":"DAT-2.C.1: When an item from a population can be selected only once, this is called sampling without replacement. When an item from the population can be selected more than once, this is called sampling with replacement.","tags":[]},{"id":356087,"external_key":"19.apst.0.0.1.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.2.1","label":"DAT-2.C.2","description":"DAT-2.C.2: A simple random sample (SRS) is a sample in which every group of a given size has an equal chance of being chosen. This method is the basis for many types of sampling mechanisms. A few examples of mechanisms used to obtain SRSs include numbering individuals and using a random number generator to select which ones to include in the sample, ignoring repeats, using a table of random numbers, or drawing a card from a deck without replacement.","tags":[]},{"id":356088,"external_key":"19.apst.0.0.1.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.2.2","label":"DAT-2.C.3","description":"DAT-2.C.3: A stratified random sample involves the division of a population into separate groups, called strata, based on shared attributes or characteristics (homogeneous grouping). Within each stratum a simple random sample is selected, and the selected units are combined to form the sample.","tags":[]},{"id":356089,"external_key":"19.apst.0.0.1.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.2.3","label":"DAT-2.C.4","description":"DAT-2.C.4: A cluster sample involves the division of a population into smaller groups, called clusters. Ideally, there is heterogeneity within each cluster, and clusters are similar to one another in their composition. A simple random sample of clusters is selected from the population to form the sample of clusters. Data are collected from all observations in the selected clusters.","tags":[]},{"id":356090,"external_key":"19.apst.0.0.1.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.2.4","label":"DAT-2.C.5","description":"DAT-2.C.5: A systematic random sample is a method in which sample members from a population are selected according to a random starting point and a fixed, periodic interval.","tags":[]},{"id":356091,"external_key":"19.apst.0.0.1.2.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.2.5","label":"DAT-2.C.6","description":"DAT-2.C.6: A census selects all items/subjects in a population.","tags":[]}]},{"id":356092,"external_key":"19.apst.0.0.1.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.3","label":"DAT-2.D","description":"DAT-2.D: Explain why a particular sampling method is or is not appropriate for a given situation.","tags":[{"id":356093,"external_key":"19.apst.0.0.1.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.3.0","label":"DAT-2.D.1","description":"DAT-2.D.1: There are advantages and disadvantages for each sampling method depending upon the question that is to be answered and the population from which the sample will be drawn.","tags":[]}]},{"id":356094,"external_key":"19.apst.0.0.1.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.4","label":"DAT-2.E","description":"DAT-2.E: Identify potential sources of bias in sampling methods.","tags":[{"id":356095,"external_key":"19.apst.0.0.1.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.4.0","label":"DAT-2.E.1","description":"DAT-2.E.1: Bias occurs when certain responses are systematically favored over others.","tags":[]},{"id":356096,"external_key":"19.apst.0.0.1.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.4.1","label":"DAT-2.E.2","description":"DAT-2.E.2: When a sample is comprised entirely of volunteers or people who choose to participate, the sample will typically not be representative of the population (voluntary response bias).","tags":[]},{"id":356097,"external_key":"19.apst.0.0.1.4.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.4.2","label":"DAT-2.E.3","description":"DAT-2.E.3: When part of the population has a reduced chance of being included in the sample, the sample will typically not be representative of the population (undercoverage bias).","tags":[]},{"id":356098,"external_key":"19.apst.0.0.1.4.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.4.3","label":"DAT-2.E.4","description":"DAT-2.E.4: Individuals chosen for the sample for whom data cannot be obtained (or who refuse to respond) may differ from those for whom data can be obtained (nonresponse bias).","tags":[]},{"id":356099,"external_key":"19.apst.0.0.1.4.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.4.4","label":"DAT-2.E.5","description":"DAT-2.E.5: Problems in the data gathering instrument or process result in response bias. Examples include questions that are confusing or leading (question wording bias) and self-reported responses.","tags":[]},{"id":356100,"external_key":"19.apst.0.0.1.4.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.1.4.5","label":"DAT-2.E.6","description":"DAT-2.E.6: Non-random sampling methods (for example, samples chosen by convenience or voluntary response) introduce potential for bias because they do not use chance to select the individuals.","tags":[]}]}]},{"id":356101,"external_key":"19.apst.0.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2","label":"DAT-3","description":"DAT-3: Significance testing allows us to make decisions about hypotheses within a particular context.","tags":[{"id":356102,"external_key":"19.apst.0.0.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.0","label":"DAT-3.A","description":"DAT-3.A: Interpret the p-value of a hypothesis test for a population proportion.","tags":[{"id":356103,"external_key":"19.apst.0.0.2.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.0.0","label":"DAT-3.A.1","description":"DAT-3.A.1: The p-value is the proportion of values for the null distribution that are as extreme or more extreme than the observed value of the test statistic. This is-  a. The proportion at or above the observed value of the test statistic, if the alternative is >.  b. The proportion at or below the observed value of the test statistic, if the alternative is <.  c. The proportion less than or equal to the negative of the absolute value of the test statistic plus the proportion greater than or equal to the absolute value of the test statistic, if the alternative is ≠.","tags":[]},{"id":356104,"external_key":"19.apst.0.0.2.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.0.1","label":"DAT-3.A.2","description":"DAT-3.A.2: An interpretation of the p-value of a significance test for a one-sample proportion should recognize that the p-value is computed by assuming that the probability model and null hypothesis are true, i.e. by assuming that the true population proportion is equal to the particular value stated in the null hypothesis.","tags":[]}]},{"id":356105,"external_key":"19.apst.0.0.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1","label":"DAT-3.B","description":"DAT-3.B: Justify a claim about the population based on the results of a significance test for a population proportion.","tags":[{"id":356106,"external_key":"19.apst.0.0.2.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.0","label":"DAT-3.B.1","description":"DAT-3.B.1: The significance level, α, is the predetermined probability of rejecting the null hypothesis given that it is true.","tags":[]},{"id":356107,"external_key":"19.apst.0.0.2.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.1","label":"DAT-3.B.2","description":"DAT-3.B.2: A formal decision explicitly compares the p-value to the significance level, α. If the p-value ≤ α , reject the null hypothesis. If the p-value > α, fail to reject the null hypothesis.","tags":[]},{"id":356108,"external_key":"19.apst.0.0.2.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.2","label":"DAT-3.B.3","description":"DAT-3.B.3: Rejecting the null hypothesis means there is sufficient statistical evidence to support the alternative hypothesis. Failing to reject the null means there is insufficient statistical evidence to support the alternative hypothesis.","tags":[]},{"id":356109,"external_key":"19.apst.0.0.2.1.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.3","label":"DAT-3.B.4","description":"DAT-3.B.4: The conclusion about the alternative hypothesis must be stated in context.","tags":[]},{"id":356110,"external_key":"19.apst.0.0.2.1.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.4","label":"DAT-3.B.5","description":"DAT-3.B.5: A significance test can lead to rejecting or not rejecting the null hypothesis, but can never lead to concluding or proving that the null hypothesis is true. Lack of statistical evidence for the alternative hypothesis is not the same as evidence for the null hypothesis.","tags":[]},{"id":356111,"external_key":"19.apst.0.0.2.1.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.5","label":"DAT-3.B.6","description":"DAT-3.B.6: Small p-values indicate that the observed value of the test statistic would be unusual if the null hypothesis and probability model were true, and so provide evidence for the alternative. The lower the p-value, the more convincing the statistical evidence for the alternative hypothesis.","tags":[]},{"id":356112,"external_key":"19.apst.0.0.2.1.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.6","label":"DAT-3.B.7","description":"DAT-3.B.7: p-values that are not small indicate that the observed value of the test statistic would not be unusual if the null hypothesis and probability model were true, so do not provide convincing statistical evidence for the alternative hypothesis nor do they provide evidence that the null hypothesis is true.","tags":[]},{"id":356113,"external_key":"19.apst.0.0.2.1.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.7","label":"DAT-3.B.8","description":"DAT-3.B.8: A formal decision explicitly compares the p-value to the significance α. If the p-value < α, then reject the null hypothesis, H₀ is p = p₀. If the p-value > α, then fail to reject the null hypothesis.","tags":[]},{"id":356114,"external_key":"19.apst.0.0.2.1.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.1.8","label":"DAT-3.B.9","description":"DAT-3.B.9: The results of a significance test for a population proportion can serve as the statistical reasoning to support the answer to a research question about the population that was sampled.","tags":[]}]},{"id":356115,"external_key":"19.apst.0.0.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.2","label":"DAT-3.C","description":"DAT-3.C: Interpret the p-value of a significance test for a difference of population proportions.","tags":[{"id":356116,"external_key":"19.apst.0.0.2.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.2.0","label":"DAT-3.C.1","description":"DAT-3.C.1: An interpretation of the p-value of a significance test for a difference of two population proportions should recognize that the p-value is computed by assuming that the null hypothesis is true, i.e., by assuming that the true population proportions are equal to each other.","tags":[]}]},{"id":356117,"external_key":"19.apst.0.0.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.3","label":"DAT-3.D","description":"DAT-3.D: Justify a claim about the population based on the results of a significance test for a difference of population proportions.","tags":[{"id":356118,"external_key":"19.apst.0.0.2.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.3.0","label":"DAT-3.D.1","description":"DAT-3.D.1: A formal decision explicitly compares the p-value to the significance α. If the p-value < α, then reject the null hypothesis, H₀ is p₁ = p₂, or H₀ is p₁ - p₂ = 0. If the p-value > α, then fail to reject the null hypothesis.","tags":[]},{"id":356119,"external_key":"19.apst.0.0.2.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.3.1","label":"DAT-3.D.2","description":"DAT-3.D.2: The results of a significance test for a difference of two population proportions can serve as the statistical reasoning to support the answer to a research question about the two populations that were sampled.","tags":[]}]},{"id":356120,"external_key":"19.apst.0.0.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.4","label":"DAT-3.E","description":"DAT-3.E: Interpret the p-value of a significance test for a population mean, including the mean difference between values in matched pairs.","tags":[{"id":356121,"external_key":"19.apst.0.0.2.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.4.0","label":"DAT-3.E.1","description":"DAT-3.E.1: An interpretation of the p-value of a significance test for a population mean should recognize that the p-value is computed by assuming that the null hypothesis is true, i.e., by assuming that the true population mean is equal to the particular value stated in the null hypothesis.","tags":[]}]},{"id":356122,"external_key":"19.apst.0.0.2.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.5","label":"DAT-3.F","description":"DAT-3.F: Justify a claim about the population based on the results of a significance test for a population mean.","tags":[{"id":356123,"external_key":"19.apst.0.0.2.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.5.0","label":"DAT-3.F.1","description":"DAT-3.F.1: A formal decision explicitly compares the p-value to the significance α. If the p-value < α, then reject the null hypothesis, H₀ is μ = μ₀. If the p-value > α, then fail to reject the null hypothesis.","tags":[]},{"id":356124,"external_key":"19.apst.0.0.2.5.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.5.1","label":"DAT-3.F.2","description":"DAT-3.F.2: The results of a significance test for a population mean can serve as the statistical reasoning to support the answer to a research question about the population that was sampled.","tags":[]}]},{"id":356125,"external_key":"19.apst.0.0.2.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.6","label":"DAT-3.G","description":"DAT-3.G: Interpret the p-value of a significance test for a difference of population means.","tags":[{"id":356126,"external_key":"19.apst.0.0.2.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.6.0","label":"DAT-3.G.1","description":"DAT-3.G.1: An interpretation of the p-value of a significance test for a two-sample difference of population means should recognize that the p-value is computed by assuming that the null hypothesis is true, i.e., by assuming that the true population means are equal to each other.","tags":[]}]},{"id":356127,"external_key":"19.apst.0.0.2.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.7","label":"DAT-3.H","description":"DAT-3.H: Justify a claim about the population based on the results of a significance test for a difference of two population means in context.","tags":[{"id":356128,"external_key":"19.apst.0.0.2.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.7.0","label":"DAT-3.H.1","description":"DAT-3.H.1: A formal decision explicitly compares the p-value to the significance α. If the p-value < α, then reject the null hypothesis, H₀ is μ₁ - µ₂ = 0, or H₀ is μ₁ = µ₂. If the p-value > α, then fail to reject the null hypothesis.","tags":[]},{"id":356129,"external_key":"19.apst.0.0.2.7.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.7.1","label":"DAT-3.H.2","description":"DAT-3.H.2: The results of a significance test for a two-sample test for a difference between two population means can serve as the statistical reasoning to support the answer to a research question about the populations that were sampled.","tags":[]}]},{"id":356130,"external_key":"19.apst.0.0.2.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.8","label":"DAT-3.I","description":"DAT-3.I: Interpret the p-value for the chi-square test for goodness of fit.","tags":[{"id":356131,"external_key":"19.apst.0.0.2.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.8.0","label":"DAT-3.I.1","description":"DAT-3.I.1: An interpretation of the p-value for the chi-square test for goodness of fit is the probability, given the null hypothesis and probability model are true, of obtaining a test statistic as, or more, extreme than the observed value.","tags":[]}]},{"id":356132,"external_key":"19.apst.0.0.2.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.9","label":"DAT-3.J","description":"DAT-3.J: Justify a claim about the population based on the results of a chi-square test for goodness of fit.","tags":[{"id":356133,"external_key":"19.apst.0.0.2.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.9.0","label":"DAT-3.J.1","description":"DAT-3.J.1: A decision to either reject or fail to reject the null hypothesis is based on comparison of the p-value to the significance level, α.","tags":[]},{"id":356134,"external_key":"19.apst.0.0.2.9.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.9.1","label":"DAT-3.J.2","description":"DAT-3.J.2: The results of a chi-square test for goodness of fit can serve as the statistical reasoning to support the answer to a research question about the population that was sampled.","tags":[]}]},{"id":356135,"external_key":"19.apst.0.0.2.10","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.10","label":"DAT-3.K","description":"DAT-3.K: Interpret the p-value for the chi-square test for homogeneity or independence.","tags":[{"id":356136,"external_key":"19.apst.0.0.2.10.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.10.0","label":"DAT-3.K.1","description":"DAT-3.K.1: An interpretation of the p-value for the chi-square test for homogeneity or independence is the probability, given the null hypothesis and probability model are true, of obtaining a test statistic as, or more, extreme than the observed value.","tags":[]}]},{"id":356137,"external_key":"19.apst.0.0.2.11","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.11","label":"DAT-3.L","description":"DAT-3.L: Justify a claim about the population based on the results of a chi-square test for homogeneity or independence.","tags":[{"id":356138,"external_key":"19.apst.0.0.2.11.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.11.0","label":"DAT-3.L.1","description":"DAT-3.L.1: A decision to either reject or fail to reject the null hypothesis for a chi-square test for homogeneity or independence is based on comparison of the p-value to the significance level, α.","tags":[]},{"id":356139,"external_key":"19.apst.0.0.2.11.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.11.1","label":"DAT-3.L.2","description":"DAT-3.L.2: The results of a chi-square test for homogeneity or independence can serve as the statistical reasoning to support the answer to a research question about the population that was sampled (independence) or the populations that were sampled (homogeneity).","tags":[]}]},{"id":356140,"external_key":"19.apst.0.0.2.12","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.12","label":"DAT-3.M","description":"DAT-3.M: Interpret the p-value of a significance test for the slope of a regression model.","tags":[{"id":356141,"external_key":"19.apst.0.0.2.12.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.12.0","label":"DAT-3.M.1","description":"DAT-3.M.1: An interpretation of the p-value of a significance test for the slope of a regression model should recognize that the p-value is computed by assuming that the null hypothesis is true, i.e. by assuming that the true population slope is equal to the particular value stated in the null hypothesis.","tags":[]}]},{"id":356142,"external_key":"19.apst.0.0.2.13","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.13","label":"DAT-3.N","description":"DAT-3.N: Justify a claim about the population based on the results of a significance test for the slope of a regression model.","tags":[{"id":356143,"external_key":"19.apst.0.0.2.13.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.13.0","label":"DAT-3.N.1","description":"DAT-3.N.1: A formal decision explicitly compares the p-value to the significance α. If the p-value < α, then reject the null hypothesis, H₀ is β = β₀. If the p-value > α, then fail to reject the null hypothesis.","tags":[]},{"id":356144,"external_key":"19.apst.0.0.2.13.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.0.2.13.1","label":"DAT-3.N.2","description":"DAT-3.N.2: The results of a significance test for the slope of a regression model can serve as the statistical reasoning to support the answer to a research question about that sample.","tags":[]}]}]}]},{"id":356145,"external_key":"19.apst.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1","label":"UNC","description":"UNC: Patterns and Uncertainty","tags":[{"id":356146,"external_key":"19.apst.0.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0","label":"UNC-1","description":"UNC-1: Graphical representations and statistics allow us to identify and represent key features of data.","tags":[{"id":356147,"external_key":"19.apst.0.1.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.0","label":"UNC-1.A","description":"UNC-1.A: Represent categorical data using frequency or relative frequency tables.","tags":[{"id":356148,"external_key":"19.apst.0.1.0.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.0.0","label":"UNC-1.A.1","description":"UNC-1.A.1: A frequency table gives the number of cases falling into each category. A relative frequency table gives the proportion of cases falling into each category.","tags":[]}]},{"id":356149,"external_key":"19.apst.0.1.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.1","label":"UNC-1.B","description":"UNC-1.B: Describe categorical data represented in frequency or relative tables.","tags":[{"id":356150,"external_key":"19.apst.0.1.0.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.1.0","label":"UNC-1.B.1","description":"UNC-1.B.1: Percentages, relative frequencies, and rates all provide the same information as proportions.","tags":[]},{"id":356151,"external_key":"19.apst.0.1.0.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.1.1","label":"UNC-1.B.2","description":"UNC-1.B.2: Counts and relative frequencies of categorical data reveal information that can be used to justify claims about the data in context.","tags":[]}]},{"id":356152,"external_key":"19.apst.0.1.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.2","label":"UNC-1.C","description":"UNC-1.C: Represent categorical data graphically.","tags":[{"id":356153,"external_key":"19.apst.0.1.0.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.2.0","label":"UNC-1.C.1","description":"UNC-1.C.1: Bar charts (or bar graphs) are used to display frequencies (counts) or relative frequencies (proportions) for categorical data.","tags":[]},{"id":356154,"external_key":"19.apst.0.1.0.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.2.1","label":"UNC-1.C.2","description":"UNC-1.C.2: The height or length of each bar in a bar graph corresponds to either the number or proportion of observations falling within each category.","tags":[]},{"id":356155,"external_key":"19.apst.0.1.0.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.2.2","label":"UNC-1.C.3","description":"UNC-1.C.3: There are many additional ways to represent frequencies (counts) or relative frequencies (proportions) for categorical data.","tags":[]}]},{"id":356156,"external_key":"19.apst.0.1.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.3","label":"UNC-1.D","description":"UNC-1.D: Describe categorical data represented graphically.","tags":[{"id":356157,"external_key":"19.apst.0.1.0.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.3.0","label":"UNC-1.D.1","description":"UNC-1.D.1: Graphical representations of a categorical variable reveal information that can be used to justify claims about the data in context.","tags":[]}]},{"id":356158,"external_key":"19.apst.0.1.0.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.4","label":"UNC-1.E","description":"UNC-1.E: Compare multiple sets of categorical data.","tags":[{"id":356159,"external_key":"19.apst.0.1.0.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.4.0","label":"UNC-1.E.1","description":"UNC-1.E.1: Frequency tables, bar graphs, or other representations can be used to compare two or more data sets in terms of the same categorical variable.","tags":[]}]},{"id":356160,"external_key":"19.apst.0.1.0.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.5","label":"UNC-1.F","description":"UNC-1.F: Classify types of quantitative variables.","tags":[{"id":356161,"external_key":"19.apst.0.1.0.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.5.0","label":"UNC-1.F.1","description":"UNC-1.F.1: A discrete variable can take on a countable number of values. The number of values may be finite or countably infinite, as with the counting numbers.","tags":[]},{"id":356162,"external_key":"19.apst.0.1.0.5.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.5.1","label":"UNC-1.F.2","description":"UNC-1.F.2: A continuous variable can take on infinitely many values, but those values cannot be counted. No matter how small the interval between two values of a continuous variable, it is always possible to determine another value between them.","tags":[]}]},{"id":356163,"external_key":"19.apst.0.1.0.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.6","label":"UNC-1.G","description":"UNC-1.G: Represent quantitative data graphically.","tags":[{"id":356164,"external_key":"19.apst.0.1.0.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.6.0","label":"UNC-1.G.1","description":"UNC-1.G.1: In a histogram, the height of each bar shows the number or proportion of observations that fall within the interval corresponding to that bar. Altering the interval widths can change the appearance of the histogram.","tags":[]},{"id":356165,"external_key":"19.apst.0.1.0.6.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.6.1","label":"UNC-1.G.2","description":"UNC-1.G.2: In a stem and leaf plot, each data value is split into a \"stem\" (the first digit or digits) and a \"leaf\" (usually the last digit).","tags":[]},{"id":356166,"external_key":"19.apst.0.1.0.6.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.6.2","label":"UNC-1.G.3","description":"UNC-1.G.3: A dotplot represents each observation by a dot, with the position on the horizontal axis corresponding to the data value of that observation, with nearly identical values stacked on top of each other.","tags":[]},{"id":356167,"external_key":"19.apst.0.1.0.6.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.6.3","label":"UNC-1.G.4","description":"UNC-1.G.4: A cumulative graph represents the number or proportion of a data set less than or equal to a given number.","tags":[]},{"id":356168,"external_key":"19.apst.0.1.0.6.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.6.4","label":"UNC-1.G.5","description":"UNC-1.G.5: There are many additional ways to graphically represent distributions of quantitative data.","tags":[]}]},{"id":356169,"external_key":"19.apst.0.1.0.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.7","label":"UNC-1.H","description":"UNC-1.H: Describe the characteristics of quantitative data distributions.","tags":[{"id":356170,"external_key":"19.apst.0.1.0.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.7.0","label":"UNC-1.H.1","description":"UNC-1.H.1: Descriptions of the distribution of quantitative data include shape, center, and variability (spread), as well as any unusual features such as outliers, gaps, clusters, or multiple peaks.","tags":[]},{"id":356171,"external_key":"19.apst.0.1.0.7.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.7.1","label":"UNC-1.H.2","description":"UNC-1.H.2: Outliers for one-variable data are data points that are unusually small or large relative to the rest of the data.","tags":[]},{"id":356172,"external_key":"19.apst.0.1.0.7.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.7.2","label":"UNC-1.H.3","description":"UNC-1.H.3: A distribution is skewed to the right (positive skew) if the right tail is longer than the left. A distribution is skewed to the left (negative skew) if the left tail is longer than the right. A distribution is symmetric if the left half is the mirror image of the right half.","tags":[]},{"id":356173,"external_key":"19.apst.0.1.0.7.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.7.3","label":"UNC-1.H.4","description":"UNC-1.H.4: Univariate graphs with one main peak are known as unimodal. Graphs with two prominent peaks are bimodal. A graph where each bar height is approximately the same (no prominent peaks) is approximately uniform.","tags":[]},{"id":356174,"external_key":"19.apst.0.1.0.7.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.7.4","label":"UNC-1.H.5","description":"UNC-1.H.5: A gap is a region of a distribution between two data values where there are no observed data.","tags":[]},{"id":356175,"external_key":"19.apst.0.1.0.7.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.7.5","label":"UNC-1.H.6","description":"UNC-1.H.6: Clusters are concentrations of data usually separated by gaps.","tags":[]},{"id":356176,"external_key":"19.apst.0.1.0.7.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.7.6","label":"UNC-1.H.7","description":"UNC-1.H.7: Descriptive statistics does not attribute properties of a data set to a larger population, but may provide the basis for conjectures for subsequent testing.","tags":[]}]},{"id":356177,"external_key":"19.apst.0.1.0.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.8","label":"UNC-1.I","description":"UNC-1.I: Calculate measures of center and position for quantitative data.","tags":[{"id":356178,"external_key":"19.apst.0.1.0.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.8.0","label":"UNC-1.I.1","description":"UNC-1.I.1: A statistic is a numerical summary of sample data.","tags":[]},{"id":356179,"external_key":"19.apst.0.1.0.8.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.8.1","label":"UNC-1.I.2","description":"UNC-1.I.2: The mean is the sum of all the data values divided by the number of values. For a sample, the mean is denoted by x-bar- x-bar = (1/n)∑ from i = 1 to n of x_i, where x_i represents the ith data point in the sample and n represents the number of data values in the sample.","tags":[]},{"id":356180,"external_key":"19.apst.0.1.0.8.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.8.2","label":"UNC-1.I.3","description":"UNC-1.I.3: The median of a data set is the middle value when data are ordered. When the number of data points is even, the median can take on any value between the two middle values. In AP Statistics, the most commonly used value for the median of a data set with an even number of values is the average of the two middle values.","tags":[]},{"id":356181,"external_key":"19.apst.0.1.0.8.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.8.3","label":"UNC-1.I.4","description":"UNC-1.I.4: The first quartile, Q1, is the median of the half of the ordered data set from the minimum to the position of the median. The third quartile, Q3, is the median of the half of the ordered data set from the position of the median to the maximum. Q1 and Q3 form the boundaries for the middle 50% of values in an ordered data set.","tags":[]},{"id":356182,"external_key":"19.apst.0.1.0.8.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.8.4","label":"UNC-1.I.5","description":"UNC-1.I.5: The pth percentile is interpreted as the value that has p% of the data less than or equal to it.","tags":[]}]},{"id":356183,"external_key":"19.apst.0.1.0.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.9","label":"UNC-1.J","description":"UNC-1.J: Calculate measures of variability for quantitative data.","tags":[{"id":356184,"external_key":"19.apst.0.1.0.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.9.0","label":"UNC-1.J.1","description":"UNC-1.J.1: Three commonly used measures of variability (or spread) in a distribution are the range, interquartile range, and standard deviation.","tags":[]},{"id":356185,"external_key":"19.apst.0.1.0.9.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.9.1","label":"UNC-1.J.2","description":"UNC-1.J.2: The range is defined as the difference between the maximum data value and the minimum data value. The interquartile range (IQR) is defined as the difference between the third and first quartiles- Q3 - Q1. Both the range and the interquartile range are possible ways of measuring variability of the distribution of a quantitative variable.","tags":[]},{"id":356186,"external_key":"19.apst.0.1.0.9.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.9.2","label":"UNC-1.J.3","description":"UNC-1.J.3: Standard deviation is a way to measure variability of the distribution of a quantitative variable. For a sample, the standard deviation is denoted by s- s_x = √[(1/(n - 1))∑(x_i - x-bar)²]. The square of the sample standard deviation, s², is called the sample variance.","tags":[]},{"id":356187,"external_key":"19.apst.0.1.0.9.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.9.3","label":"UNC-1.J.4","description":"UNC-1.J.4: Changing units of measurement affects the values of the calculated statistics.","tags":[]}]},{"id":356188,"external_key":"19.apst.0.1.0.10","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.10","label":"UNC-1.K","description":"UNC-1.K: Explain the selection of a particular measure of center and/or variability for describing a set of quantitative data.","tags":[{"id":356189,"external_key":"19.apst.0.1.0.10.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.10.0","label":"UNC-1.K.1","description":"UNC-1.K.1: There are many methods for determining outliers. Two methods frequently used in this course are- a. An outlier is a value greater than 1.5 x IQR above the third quartile or more than 1.5 x IQR below the first quartile. b. An outlier is a value located 2 or more standard deviations above, or below, the mean.","tags":[]},{"id":356190,"external_key":"19.apst.0.1.0.10.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.10.1","label":"UNC-1.K.2","description":"UNC-1.K.2: The mean, standard deviation, and range are considered nonresistant (or non-robust) because they are influenced by outliers. The median and IQR are considered resistant (or robust) because outliers do not greatly (if at all) affect their value.","tags":[]}]},{"id":356191,"external_key":"19.apst.0.1.0.11","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.11","label":"UNC-1.L","description":"UNC-1.L: Represent summary statistics for quantitative data graphically.","tags":[{"id":356192,"external_key":"19.apst.0.1.0.11.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.11.0","label":"UNC-1.L.1","description":"UNC-1.L.1: Taken together, the minimum data value, the first quartile (Q1), the median, the third quartile (Q3), and the maximum data value make up the five-number summary.","tags":[]},{"id":356193,"external_key":"19.apst.0.1.0.11.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.11.1","label":"UNC-1.L.2","description":"UNC-1.L.2: A boxplot is a graphical representation of the five-number summary (minimum, first quartile, median, third quartile, maximum). The box represents the middle 50% of data, with a line at the median and the ends of the box corresponding to the quartiles. Lines (\"whiskers\") extend from the quartiles to the most extreme point that is not an outlier, and outliers are indicated by their own symbol beyond this.","tags":[]}]},{"id":356194,"external_key":"19.apst.0.1.0.12","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.12","label":"UNC-1.M","description":"UNC-1.M: Describe summary statistics of quantitative data represented graphically.","tags":[{"id":356195,"external_key":"19.apst.0.1.0.12.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.12.0","label":"UNC-1.M.1","description":"UNC-1.M.1: Summary statistics of quantitative data, or of sets of quantitative data, can be used to justify claims about the data in context.","tags":[]},{"id":356196,"external_key":"19.apst.0.1.0.12.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.12.1","label":"UNC-1.M.2","description":"UNC-1.M.2: If a distribution is relatively symmetric, then the mean and median are relatively close to one another. If a distribution is skewed right, then the mean is usually to the right of the median. If the distribution is skewed left, then the mean is usually to the left of the median.","tags":[]}]},{"id":356197,"external_key":"19.apst.0.1.0.13","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.13","label":"UNC-1.N","description":"UNC-1.N: Compare graphical representations for multiple sets of quantitative data.","tags":[{"id":356198,"external_key":"19.apst.0.1.0.13.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.13.0","label":"UNC-1.N.1","description":"UNC-1.N.1: Any of the graphical representations, e.g. histograms, side-by-side boxplots, etc., can be used to compare two or more independent samples on center, variability, clusters, gaps, outliers, and other features.","tags":[]}]},{"id":356199,"external_key":"19.apst.0.1.0.14","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.14","label":"UNC-1.O","description":"UNC-1.O: Compare summary statistics for multiple sets of quantitative data.","tags":[{"id":356200,"external_key":"19.apst.0.1.0.14.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.14.0","label":"UNC-1.O.1","description":"UNC-1.O.1: Any of the numerical summaries (e.g., mean, standard deviation, relative frequency, etc.) can be used to compare two or more independent samples.","tags":[]}]},{"id":356201,"external_key":"19.apst.0.1.0.15","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.15","label":"UNC-1.P","description":"UNC-1.P: Compare numerical and graphical representations for two categorical variables.","tags":[{"id":356202,"external_key":"19.apst.0.1.0.15.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.15.0","label":"UNC-1.P.1","description":"UNC-1.P.1: Side-by-side bar graphs, segmented bar graphs, and mosaic plots are examples of bar graphs for one categorical variable, broken down by categories of another categorical variable.","tags":[]},{"id":356203,"external_key":"19.apst.0.1.0.15.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.15.1","label":"UNC-1.P.2","description":"UNC-1.P.2: Graphical representations of two categorical variables can be used to compare distributions and/or determine if variables are associated.","tags":[]},{"id":356204,"external_key":"19.apst.0.1.0.15.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.15.2","label":"UNC-1.P.3","description":"UNC-1.P.3: A two-way table, also called a contingency table, is used to summarize two categorical variables. The entries in the cells can be frequency counts or relative frequencies.","tags":[]},{"id":356205,"external_key":"19.apst.0.1.0.15.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.15.3","label":"UNC-1.P.4","description":"UNC-1.P.4: A joint relative frequency is a cell frequency divided by the total for the entire table.","tags":[]}]},{"id":356206,"external_key":"19.apst.0.1.0.16","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.16","label":"UNC-1.Q","description":"UNC-1.Q: Calculate statistics for two categorical variables.","tags":[{"id":356207,"external_key":"19.apst.0.1.0.16.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.16.0","label":"UNC-1.Q.1","description":"UNC-1.Q.1: The marginal relative frequencies are the row and column totals in a two-way table divided by the total for the entire table.","tags":[]},{"id":356208,"external_key":"19.apst.0.1.0.16.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.16.1","label":"UNC-1.Q.2","description":"UNC-1.Q.2: A conditional relative frequency is a relative frequency for a specific part of the contingency table (e.g. cell frequencies in a row divided by the total for that row).","tags":[]}]},{"id":356209,"external_key":"19.apst.0.1.0.17","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.17","label":"UNC-1.R","description":"UNC-1.R: Compare statistics for two categorical variables.","tags":[{"id":356210,"external_key":"19.apst.0.1.0.17.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.17.0","label":"UNC-1.R.1","description":"UNC-1.R.1: Summary statistics for two categorical variables can be used to compare distributions and/or determine if variables are associated.","tags":[]}]},{"id":356211,"external_key":"19.apst.0.1.0.18","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.18","label":"UNC-1.S","description":"UNC-1.S: Represent bivariate quantitative data using scatterplots.","tags":[{"id":356212,"external_key":"19.apst.0.1.0.18.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.18.0","label":"UNC-1.S.1","description":"UNC-1.S.1: A bivariate quantitative data set consists of observations of two different quantitative variables made on individuals in a sample or population.","tags":[]},{"id":356213,"external_key":"19.apst.0.1.0.18.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.18.1","label":"UNC-1.S.2","description":"UNC-1.S.2: A scatterplot shows two numeric values for each observation, one corresponding to the value on the x-axis and one corresponding to the value on the y-axis.","tags":[]},{"id":356214,"external_key":"19.apst.0.1.0.18.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.0.18.2","label":"UNC-1.S.3","description":"UNC-1.S.3: An explanatory variable is a variable whose values are used to explain or predict corresponding values for the response variable.","tags":[]}]}]},{"id":356215,"external_key":"19.apst.0.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.1","label":"UNC-2","description":"UNC-2: Simulation allows us to anticipate patterns in data.","tags":[{"id":356216,"external_key":"19.apst.0.1.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.1.0","label":"UNC-2.A","description":"UNC-2.A: Estimate probabilities using simulation.","tags":[{"id":356217,"external_key":"19.apst.0.1.1.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.1.0.0","label":"UNC-2.A.1","description":"UNC-2.A.1: A random process generates results that are determined by chance.","tags":[]},{"id":356218,"external_key":"19.apst.0.1.1.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.1.0.1","label":"UNC-2.A.2","description":"UNC-2.A.2: An outcome is the result of a trial of a random process.","tags":[]},{"id":356219,"external_key":"19.apst.0.1.1.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.1.0.2","label":"UNC-2.A.3","description":"UNC-2.A.3: An event is a collection of outcomes.","tags":[]},{"id":356220,"external_key":"19.apst.0.1.1.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.1.0.3","label":"UNC-2.A.4","description":"UNC-2.A.4: Simulation is a way to model random events, such that simulated outcomes closely match real world outcomes. All possible outcomes are associated with a value to be determined by chance. Record the counts of simulated outcomes and the count total.","tags":[]},{"id":356221,"external_key":"19.apst.0.1.1.0.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.1.0.4","label":"UNC-2.A.5","description":"UNC-2.A.5: The relative frequency of an outcome or event in simulated or empirical data can be used to estimate the probability of that outcome or event.","tags":[]},{"id":356222,"external_key":"19.apst.0.1.1.0.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.1.0.5","label":"UNC-2.A.6","description":"UNC-2.A.6: The law of large numbers states that simulated (empirical) probabilities tend to get closer to the true probability as the number of trials increases.","tags":[]}]}]},{"id":356223,"external_key":"19.apst.0.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2","label":"UNC-3","description":"UNC-3: Probabilistic reasoning allows us to anticipate patterns in data.","tags":[{"id":356224,"external_key":"19.apst.0.1.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.0","label":"UNC-3.A","description":"UNC-3.A: Estimate probabilities of binomial random variables using data from a simulation.","tags":[{"id":356225,"external_key":"19.apst.0.1.2.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.0.0","label":"UNC-3.A.1","description":"UNC-3.A.1: A probability distribution can be constructed using the rules of probability or estimated with a simulation using random number generators","tags":[]},{"id":356226,"external_key":"19.apst.0.1.2.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.0.1","label":"UNC-3.A.2","description":"UNC-3.A.2: A binomial random variable, X, counts the number of successes in n repeated independent trials, each trial having two possible outcomes (success or failure), with the probability of success p and the probability of failure 1 - p.","tags":[]}]},{"id":356227,"external_key":"19.apst.0.1.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.1","label":"UNC-3.B","description":"UNC-3.B: Calculate probabilities for a binomial distribution.","tags":[{"id":356228,"external_key":"19.apst.0.1.2.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.1.0","label":"UNC-3.B.1","description":"UNC-3.B.1: The probability that a binomial random variable, X, has exactly x successes for n independent trials, when the probability of success is p, is calculated as P(X = k) = [n_C_k](p^k)[(1 - p)^(n-k)], x = 0, 1, 2, …, n. This is the binomial probability function.","tags":[]}]},{"id":356229,"external_key":"19.apst.0.1.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.2","label":"UNC-3.C","description":"UNC-3.C: Calculate parameters for a binomial distribution.","tags":[{"id":356230,"external_key":"19.apst.0.1.2.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.2.0","label":"UNC-3.C.1","description":"UNC-3.C.1: If a random variable is binomial, its mean, μ_x, is n∙p and its standard deviation, sigma_x, is √[(n∙p)(1 - p)].","tags":[]}]},{"id":356231,"external_key":"19.apst.0.1.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.3","label":"UNC-3.D","description":"UNC-3.D: Interpret probabilities and parameters for a binomial distribution.","tags":[{"id":356232,"external_key":"19.apst.0.1.2.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.3.0","label":"UNC-3.D.1","description":"UNC-3.D.1: Probabilities and parameters for a binomial distribution should be interpreted using appropriate units and within the context of a specific population or situation.","tags":[]}]},{"id":356233,"external_key":"19.apst.0.1.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.4","label":"UNC-3.E","description":"UNC-3.E: Calculate probabilities for geometric random variables.","tags":[{"id":356234,"external_key":"19.apst.0.1.2.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.4.0","label":"UNC-3.E.1","description":"UNC-3.E.1: For a sequence of independent trials, a geometric random variable, X, gives the number of the trial on which the first success occurs. Each trial has two possible outcomes (success or failure) with the probability of success p and the probability of failure 1 - p.","tags":[]},{"id":356235,"external_key":"19.apst.0.1.2.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.4.1","label":"UNC-3.E.2","description":"UNC-3.E.2: The probability that the first success for repeated independent trials with probability of success p occurs on trial x is calculated as P(X = k) = (p)(1 - p)k-1, x = 1, 2, 3, ….This is the geometric probability function.","tags":[]}]},{"id":356236,"external_key":"19.apst.0.1.2.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.5","label":"UNC-3.F","description":"UNC-3.F: Calculate parameters of a geometric distribution.","tags":[{"id":356237,"external_key":"19.apst.0.1.2.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.5.0","label":"UNC-3.F.1","description":"UNC-3.F.1: If a random variable is geometric, its mean, μ_x, is 1/p and its standard deviation, sigma_x, is √(1 - p)/p.","tags":[]}]},{"id":356238,"external_key":"19.apst.0.1.2.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.6","label":"UNC-3.G","description":"UNC-3.G: Interpret probabilities and parameters for a geometric distribution.","tags":[{"id":356239,"external_key":"19.apst.0.1.2.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.6.0","label":"UNC-3.G.1","description":"UNC-3.G.1: Probabilities and parameters for a geometric distribution should be interpreted using appropriate units and within the context of a specific population or situation.","tags":[]}]},{"id":356240,"external_key":"19.apst.0.1.2.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.7","label":"UNC-3.H","description":"UNC-3.H: Estimate sampling distributions using simulation.","tags":[{"id":356241,"external_key":"19.apst.0.1.2.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.7.0","label":"UNC-3.H.1","description":"UNC-3.H.1: A sampling distribution of a statistic is the distribution of values for the statistic for all possible samples of a given size from a given population.","tags":[]},{"id":356242,"external_key":"19.apst.0.1.2.7.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.7.1","label":"UNC-3.H.2","description":"UNC-3.H.2: The central limit theorem (CLT) states that when the sample size is sufficiently large, a sampling distribution of the mean of a random variable will be approximately normally distributed.","tags":[]},{"id":356243,"external_key":"19.apst.0.1.2.7.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.7.2","label":"UNC-3.H.3","description":"UNC-3.H.3: The central limit theorem requires that the sample values are independent of each other and that n is sufficiently large.","tags":[]},{"id":356244,"external_key":"19.apst.0.1.2.7.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.7.3","label":"UNC-3.H.4","description":"UNC-3.H.4: A randomization distribution is a collection of statistics generated by simulation assuming known values for the parameters. For a randomized experiment, this means repeatedly randomly reallocating/reassigning the response values to treatment groups.","tags":[]},{"id":356245,"external_key":"19.apst.0.1.2.7.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.7.4","label":"UNC-3.H.5","description":"UNC-3.H.5: The sampling distribution of a statistic can be simulated by generating repeated random samples from a population.","tags":[]}]},{"id":356246,"external_key":"19.apst.0.1.2.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.8","label":"UNC-3.I","description":"UNC-3.I: Explain why an estimator is or is not unbiased.","tags":[{"id":356247,"external_key":"19.apst.0.1.2.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.8.0","label":"UNC-3.I.1","description":"UNC-3.I.1: When estimating a population parameter, an estimator is unbiased if, on average, the value of the estimator is equal to the population parameter.","tags":[]}]},{"id":356248,"external_key":"19.apst.0.1.2.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.9","label":"UNC-3.J","description":"UNC-3.J: Calculate estimates for a population parameter.","tags":[{"id":356249,"external_key":"19.apst.0.1.2.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.9.0","label":"UNC-3.J.1","description":"UNC-3.J.1: When estimating a population parameter, an estimator exhibits variability that can be modeled using probability.","tags":[]},{"id":356250,"external_key":"19.apst.0.1.2.9.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.9.1","label":"UNC-3.J.2","description":"UNC-3.J.2: A sample statistic is a point estimator of the corresponding population parameter.","tags":[]}]},{"id":356251,"external_key":"19.apst.0.1.2.10","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.10","label":"UNC-3.K","description":"UNC-3.K: Determine parameters of a sampling distribution for sample proportions.","tags":[{"id":356252,"external_key":"19.apst.0.1.2.10.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.10.0","label":"UNC-3.K.1","description":"UNC-3.K.1: For independent samples (sampling with replacement) of a categorical variable from a population with population proportion, p, the sampling distribution of the sample proportion, p-hat, has a mean, μ_p-hat = p, and a standard deviation, sigma_p-hat = √[(p(1 - p))/n].","tags":[]},{"id":356253,"external_key":"19.apst.0.1.2.10.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.10.1","label":"UNC-3.K.2","description":"UNC-3.K.2: If sampling without replacement, the standard deviation of the sample proportion is smaller than what is given by the formula above. If the sample size is less than 10% of the population size, the difference is negligible.","tags":[]}]},{"id":356254,"external_key":"19.apst.0.1.2.11","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.11","label":"UNC-3.L","description":"UNC-3.L: Determine whether a sampling distribution for a sample proportion can be described as approximately normal.","tags":[{"id":356255,"external_key":"19.apst.0.1.2.11.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.11.0","label":"UNC-3.L.1","description":"UNC-3.L.1: For a categorical variable, the sampling distribution of the sample proportion, p-hat, will have an approximate normal distribution, provided the sample size is large enough- n·p ≥ 10 and n(1 - p) ≥ 10.","tags":[]}]},{"id":356256,"external_key":"19.apst.0.1.2.12","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.12","label":"UNC-3.M","description":"UNC-3.M: Interpret probabilities and parameters for a sampling distribution for a sample proportion.","tags":[{"id":356257,"external_key":"19.apst.0.1.2.12.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.12.0","label":"UNC-3.M.1","description":"UNC-3.M.1: Probabilities and parameters for a sampling distribution for a sample proportion should be interpreted using appropriate units and within the context of a specific population.","tags":[]}]},{"id":356258,"external_key":"19.apst.0.1.2.13","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.13","label":"UNC-3.N","description":"UNC-3.N: Determine parameters of a sampling distribution for a difference in sample proportions.","tags":[{"id":356259,"external_key":"19.apst.0.1.2.13.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.13.0","label":"UNC-3.N.1","description":"UNC-3.N.1: For a categorical variable, when randomly sampling with replacement from two independent populations with population proportions p₁ and p₂, the sampling distribution of the difference in sample proportions p-hat₁ - p-hat₂ has mean, μ_(p-hat₁ - p-hat₂) = p₁ - p₂ and standard deviation, sigma_(p-hat₁ - p-hat₂) = √[(p₁(1 - p₁))/n₁ + (p₂(1 - p₂))/n₂].","tags":[]},{"id":356260,"external_key":"19.apst.0.1.2.13.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.13.1","label":"UNC-3.N.2","description":"UNC-3.N.2: If sampling without replacement, the standard deviation of the difference in sample proportions is smaller than what is given by the formula above. If the sample sizes are less than 10% of the population sizes, the difference is negligible.","tags":[]}]},{"id":356261,"external_key":"19.apst.0.1.2.14","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.14","label":"UNC-3.O","description":"UNC-3.O: Determine whether a sampling distribution for a difference of sample proportions can be described as approximately normal.","tags":[{"id":356262,"external_key":"19.apst.0.1.2.14.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.14.0","label":"UNC-3.O.1","description":"UNC-3.O.1: The sampling distribution of the difference in sample proportions p-hat₁ - p-hat₂ will have an approximate normal distribution provided the sample sizes are large enough- n₁p₁ ≥ 10, n₁(1 - p₁) ≥ 10, n₂p₂ ≥ 10, n₂(1 - p₂) ≥ 10.","tags":[]}]},{"id":356263,"external_key":"19.apst.0.1.2.15","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.15","label":"UNC-3.P","description":"UNC-3.P: Interpret probabilities and parameters for a sampling distribution for a difference in proportions.","tags":[{"id":356264,"external_key":"19.apst.0.1.2.15.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.15.0","label":"UNC-3.P.1","description":"UNC-3.P.1: Parameters for a sampling distribution for a difference of proportions should be interpreted using appropriate units and within the context of a specific populations.","tags":[]}]},{"id":356265,"external_key":"19.apst.0.1.2.16","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.16","label":"UNC-3.Q","description":"UNC-3.Q: Determine parameters for a sampling distribution for sample means.","tags":[{"id":356266,"external_key":"19.apst.0.1.2.16.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.16.0","label":"UNC-3.Q.1","description":"UNC-3.Q.1: For a numerical variable, when random sampling with replacement from a population with mean μ and standard deviation, sigma, the sampling distribution of the sample mean has mean μ_x-bar = μ and standard deviation sigma_x-bar = sigma/√n.","tags":[]},{"id":356267,"external_key":"19.apst.0.1.2.16.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.16.1","label":"UNC-3.Q.2","description":"UNC-3.Q.2: If sampling without replacement, the standard deviation of the sample mean is smaller than what is given by the formula above. If the sample size is less than 10% of the population size, the difference is negligible.","tags":[]}]},{"id":356268,"external_key":"19.apst.0.1.2.17","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.17","label":"UNC-3.R","description":"UNC-3.R: Determine whether a sampling distribution of a sample mean can be described as approximately normal.","tags":[{"id":356269,"external_key":"19.apst.0.1.2.17.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.17.0","label":"UNC-3.R.1","description":"UNC-3.R.1: For a numerical variable, if the population distribution can be modeled with a normal distribution, the sampling distribution of the sample mean, x-bar, can be modeled with a normal distribution.","tags":[]},{"id":356270,"external_key":"19.apst.0.1.2.17.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.17.1","label":"UNC-3.R.2","description":"UNC-3.R.2: For a numerical variable, if the population distribution cannot be modeled with a normal distribution, the sampling distribution of the sample mean, x-bar, can be modeled approximately by a normal distribution, provided the sample size is large enough, e.g., greater than or equal to 30.","tags":[]}]},{"id":356271,"external_key":"19.apst.0.1.2.18","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.18","label":"UNC-3.S","description":"UNC-3.S: Interpret probabilities and parameters for a sampling distribution for a sample mean.","tags":[{"id":356272,"external_key":"19.apst.0.1.2.18.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.18.0","label":"UNC-3.S.1","description":"UNC-3.S.1: Probabilities and parameters for a sampling distribution for a sample mean should be interpreted using appropriate units and within the context of a specific population.","tags":[]}]},{"id":356273,"external_key":"19.apst.0.1.2.19","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.19","label":"UNC-3.T","description":"UNC-3.T: Determine parameters of a sampling distribution for a difference in sample means.","tags":[{"id":356274,"external_key":"19.apst.0.1.2.19.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.19.0","label":"UNC-3.T.1","description":"UNC-3.T.1: For a numerical variable, when randomly sampling with replacement from two independent populations with population means μ₁ and μ₂ and population standard deviations sigma₁ and sigma₂, the sampling distribution of the difference in sample means x-bar₁ - x-bar₂ has mean μ_(x-bar₁ - x-bar₂) = μ₁ - μ₂ and standard deviation, sigma_(x-bar₁ - x-bar₂) = √[(sigma²₁/n₁) + (sigma²₂/n₂)].","tags":[]},{"id":356275,"external_key":"19.apst.0.1.2.19.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.19.1","label":"UNC-3.T.2","description":"UNC-3.T.2: If sampling without replacement, the standard deviation of the difference in sample means is smaller than what is given by the formula above. If the sample sizes are less than 10% of the population sizes, the difference is negligible.","tags":[]}]},{"id":356276,"external_key":"19.apst.0.1.2.20","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.20","label":"UNC-3.U","description":"UNC-3.U: Determine whether a sampling distribution of a difference in sample means can be described as approximately normal.","tags":[{"id":356277,"external_key":"19.apst.0.1.2.20.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.20.0","label":"UNC-3.U.1","description":"UNC-3.U.1: The sampling distribution of the difference in sample means x-bar₁ - x-bar₂ can be modeled with a normal distribution if the two population distributions can be modeled with a normal distribution.","tags":[]},{"id":356278,"external_key":"19.apst.0.1.2.20.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.20.1","label":"UNC-3.U.2","description":"UNC-3.U.2: The sampling distribution of the difference in sample means x-bar₁ - x-bar₂ can be modeled approximately by a normal distribution if the two population distributions cannot be modeled with a normal distribution but both sample sizes are greater than or equal to 30.","tags":[]}]},{"id":356279,"external_key":"19.apst.0.1.2.21","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.21","label":"UNC-3.V","description":"UNC-3.V: Interpret probabilities and parameters for a sampling distribution for a difference in sample means.","tags":[{"id":356280,"external_key":"19.apst.0.1.2.21.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.2.21.0","label":"UNC-3.V.1","description":"UNC-3.V.1: Probabilities and parameters for a sampling distribution for a difference of sample means should be interpreted using appropriate units and within the context of a specific populations.","tags":[]}]}]},{"id":356281,"external_key":"19.apst.0.1.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3","label":"UNC-4","description":"UNC-4: An interval of values should be used to estimate parameters, in order to account for uncertainty.","tags":[{"id":356282,"external_key":"19.apst.0.1.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.0","label":"UNC-4.A","description":"UNC-4.A: Identify an appropriate confidence interval procedure for a population proportion.","tags":[{"id":356283,"external_key":"19.apst.0.1.3.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.0.0","label":"UNC-4.A.1","description":"UNC-4.A.1: The appropriate confidence interval procedure for a one-sample proportion for one categorical variable is a one sample z-interval for a proportion.","tags":[]}]},{"id":356284,"external_key":"19.apst.0.1.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.1","label":"UNC-4.AA","description":"UNC-4.AA: Justify a claim based on a confidence interval for a difference of population means.","tags":[{"id":356285,"external_key":"19.apst.0.1.3.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.1.0","label":"UNC-4.AA.1","description":"UNC-4.AA.1: A confidence interval for a difference of population means provides an interval of values that may provide sufficient evidence to support a particular claim in context.","tags":[]}]},{"id":356286,"external_key":"19.apst.0.1.3.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.2","label":"UNC-4.AB","description":"UNC-4.AB: Identify the effects of sample size on the width of a confidence interval for the difference of two means.","tags":[{"id":356287,"external_key":"19.apst.0.1.3.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.2.0","label":"UNC-4.AB.1","description":"UNC-4.AB.1: When all other things remain the same, the width of the confidence interval for the difference of two means tends to decrease as the sample sizes increase.","tags":[]}]},{"id":356288,"external_key":"19.apst.0.1.3.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.3","label":"UNC-4.AC","description":"UNC-4.AC: Identify an appropriate confidence interval procedure for a slope of a regression model.","tags":[{"id":356289,"external_key":"19.apst.0.1.3.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.3.0","label":"UNC-4.AC.1","description":"UNC-4.AC.1: Consider a response variable, y, that is linearly related to an explanatory variable, x. For a simple random sample of n observations, the sample regression line y-hat = a + bx, is an estimate of the population regression line mu_y = α + βx. For a particular observation, (x_i, y_i), the residual from the sample regression line, y_i - y-hat_i = y_i - (a + bx_i), is an estimate of y_i - (α + βx_i), the deviation of the response variable from the population regression line. For all points (x, y) in the population, the standard deviation of all of the deviations of the response variable from the population regression line, sigma, can be estimated by the standard deviation of the residuals from the sample regression line, s = √[(∑(y_i - y-hat_i)^2)/(n - 2)]. (Note: This formula uses n - 2 in the denominator instead of n - 1 because two parameters, α and β, must be estimated to obtain the predicted values from the least-squares regression line.)","tags":[]},{"id":356290,"external_key":"19.apst.0.1.3.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.3.1","label":"UNC-4.AC.2","description":"UNC-4.AC.2: For a simple random sample of n observations, let b represent the slope of a sample regression line. Then the mean of the sampling distribution for b equals the population slope, µ_b = β. The standard deviation of the sampling distribution for b is sigma_b = sigma/(sigma_x · √n), where sigma_x = √[(∑(x_i - x-bar)^2)/n].","tags":[]},{"id":356291,"external_key":"19.apst.0.1.3.3.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.3.2","label":"UNC-4.AC.3","description":"UNC-4.AC.3: The appropriate confidence interval for the slope of a regression model is a t-interval for the slope.","tags":[]}]},{"id":356292,"external_key":"19.apst.0.1.3.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.4","label":"UNC-4.AD","description":"UNC-4.AD: Verify the conditions to calculate confidence intervals for the slope of a regression model.","tags":[{"id":356293,"external_key":"19.apst.0.1.3.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.4.0","label":"UNC-4.AD.1","description":"UNC-4.AD.1: In order to calculate a confidence interval to estimate the slope of a regression line, we must check the following- a. The true relationship between x and y is linear. Analysis of residuals may be used to verify linearity. b. The standard deviation for y, sigma_y, does not vary with x. Analysis of residuals may be used to check for approximately equal standard deviations for all x.  c. To check for independence- i. Data should be collected using a random sample or a randomized experiment. ii. When sampling without replacement, check that n ≤ 10%N.  d. For a particular value of x, the responses (y-values) are approximately normally distributed. Analysis of graphical representations of residuals may be used to check for normality- i. If the observed distribution is skewed, n should be greater than 30.","tags":[]}]},{"id":356294,"external_key":"19.apst.0.1.3.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.5","label":"UNC-4.AE","description":"UNC-4.AE: Determine the given margin of error for the slope of a regression model.","tags":[{"id":356295,"external_key":"19.apst.0.1.3.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.5.0","label":"UNC-4.AE.1","description":"UNC-4.AE.1: For the slope of a regression line, the margin of error is the critical value (t*) times the standard error (SE) of the slope.","tags":[]},{"id":356296,"external_key":"19.apst.0.1.3.5.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.5.1","label":"UNC-4.AE.2","description":"UNC-4.AE.2: The standard error for the slope of a regression line with sample standard deviation, s, is SE = s/(s_x · √(n - 1)), where s is the estimate of sigma and s_x is the sample standard deviation of the x values.","tags":[]}]},{"id":356297,"external_key":"19.apst.0.1.3.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.6","label":"UNC-4.AF","description":"UNC-4.AF: Calculate an appropriate confidence interval for the slope of a regression model.","tags":[{"id":356298,"external_key":"19.apst.0.1.3.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.6.0","label":"UNC-4.AF.1","description":"UNC-4.AF.1: The point estimate for the slope of a regression model is the slope of the line of best fit, b.","tags":[]},{"id":356299,"external_key":"19.apst.0.1.3.6.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.6.1","label":"UNC-4.AF.2","description":"UNC-4.AF.2: For the slope of a regression model, the interval estimate is b ± t* ∙ (SE_b).","tags":[]}]},{"id":356300,"external_key":"19.apst.0.1.3.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.7","label":"UNC-4.AG","description":"UNC-4.AG: Interpret a confidence interval for the slope of a regression model.","tags":[{"id":356301,"external_key":"19.apst.0.1.3.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.7.0","label":"UNC-4.AG.1","description":"UNC-4.AG.1: In repeated random sampling with the same sample size, approximately C% of confidence intervals created will capture the slope of the regression model, i.e. the true slope of the population regression model.","tags":[]},{"id":356302,"external_key":"19.apst.0.1.3.7.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.7.1","label":"UNC-4.AG.2","description":"UNC-4.AG.2: An interpretation for a confidence interval for the slope of a regression line should include a reference to the sample taken and details about the population it represents.","tags":[]}]},{"id":356303,"external_key":"19.apst.0.1.3.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.8","label":"UNC-4.AH","description":"UNC-4.AH: Justify a claim based on a confidence interval for the slope of a regression model.","tags":[{"id":356304,"external_key":"19.apst.0.1.3.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.8.0","label":"UNC-4.AH.1","description":"UNC-4.AH.1: A confidence interval for the slope of a regression model provides an interval of values that may provide sufficient evidence to support a particular claim in context.","tags":[]}]},{"id":356305,"external_key":"19.apst.0.1.3.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.9","label":"UNC-4.AI","description":"UNC-4.AI: Identify the effects of sample size on the width of a confidence interval for the slope of a regression model.","tags":[{"id":356306,"external_key":"19.apst.0.1.3.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.9.0","label":"UNC-4.AI.1","description":"UNC-4.AI.1: When all other things remain the same, the width of the confidence interval for the slope of a regression model tends to decrease as the sample size increases.","tags":[]}]},{"id":356307,"external_key":"19.apst.0.1.3.10","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.10","label":"UNC-4.B","description":"UNC-4.B: Verify the conditions for calculating confidence intervals for a population proportion.","tags":[{"id":356308,"external_key":"19.apst.0.1.3.10.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.10.0","label":"UNC-4.B.1","description":"UNC-4.B.1: In order to make assumptions necessary for inference on population proportions, means, and slopes, we must check for independence in data collection methods and for selection of the appropriate sampling distribution.","tags":[]},{"id":356309,"external_key":"19.apst.0.1.3.10.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.10.1","label":"UNC-4.B.2","description":"UNC-4.B.2: In order to calculate a confidence interval to estimate a population proportion, p, we must check for independence and that the sampling distribution is approximately normal- a. To check for independence- i. Data should be collected using a random sample or a randomized experiment. ii. When sampling without replacement, check that n ≤ 10%N, where N is the size of the population. b. To check that the sampling distribution of p-hat is approximately normal (shape)- i. For categorical variables, check that both the number of successes, n∙p-hat, and the number of failures, n(1 - p-hat) are at least 10 so that the sample size is large enough to support an assumption of normality.","tags":[]}]},{"id":356310,"external_key":"19.apst.0.1.3.11","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.11","label":"UNC-4.C","description":"UNC-4.C: Determine the margin of error for a given sample size and an estimate for the sample size that will result in a given margin of error for a population proportion.","tags":[{"id":356311,"external_key":"19.apst.0.1.3.11.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.11.0","label":"UNC-4.C.1","description":"UNC-4.C.1: Based on sample data, the standard error of a statistic is an estimate for the standard deviation for the statistic. The standard error of p-hat is SE_(p-hat) = √[((p-hat)(1 - p-hat))/n].","tags":[]},{"id":356312,"external_key":"19.apst.0.1.3.11.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.11.1","label":"UNC-4.C.2","description":"UNC-4.C.2: A margin of error gives how much a value of a sample statistic is likely to vary from the value of the corresponding population parameter.","tags":[]},{"id":356313,"external_key":"19.apst.0.1.3.11.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.11.2","label":"UNC-4.C.3","description":"UNC-4.C.3: For categorical variables, the margin of error is the critical value (z*) times the standard error (SE) of the relevant statistic, which equals z* ∙ √[((p-hat)(1 - p-hat))/n] for a one sample proportion.","tags":[]},{"id":356314,"external_key":"19.apst.0.1.3.11.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.11.3","label":"UNC-4.C.4","description":"UNC-4.C.4: The formula for margin of error can be rearranged to solve for n, the minimum sample size needed to achieve a given margin of error. For this purpose, use a guess for p-hat or use p-hat = 0.5 in order to find an upper bound for the sample size that will result in a given margin of error.","tags":[]}]},{"id":356315,"external_key":"19.apst.0.1.3.12","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.12","label":"UNC-4.D","description":"UNC-4.D: Calculate an appropriate confidence interval for a population proportion.","tags":[{"id":356316,"external_key":"19.apst.0.1.3.12.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.12.0","label":"UNC-4.D.1","description":"UNC-4.D.1: In general, an interval estimate can be constructed as point estimate ± (margin of error). For a one-sample proportion, the interval estimate is p-hat ± z* ∙ √[((p-hat)(1 - p-hat))/n].","tags":[]},{"id":356317,"external_key":"19.apst.0.1.3.12.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.12.1","label":"UNC-4.D.2","description":"UNC-4.D.2: Critical values represent the boundaries encompassing the middle C% of the standard normal distribution, where C% is an approximate confidence level for a proportion.","tags":[]}]},{"id":356318,"external_key":"19.apst.0.1.3.13","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.13","label":"UNC-4.E","description":"UNC-4.E: Calculate an interval estimate based on a confidence interval for a population proportion.","tags":[{"id":356319,"external_key":"19.apst.0.1.3.13.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.13.0","label":"UNC-4.E.1","description":"UNC-4.E.1: Confidence intervals for population proportions can be used to calculate interval estimates with specified units.","tags":[]}]},{"id":356320,"external_key":"19.apst.0.1.3.14","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.14","label":"UNC-4.F","description":"UNC-4.F: Interpret a confidence interval for a population proportion.","tags":[{"id":356321,"external_key":"19.apst.0.1.3.14.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.14.0","label":"UNC-4.F.1","description":"UNC-4.F.1: A confidence interval for a population proportion either contains the population proportion or it does not, because each interval is based on random sample data, which varies from sample to sample.","tags":[]},{"id":356322,"external_key":"19.apst.0.1.3.14.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.14.1","label":"UNC-4.F.2","description":"UNC-4.F.2: We are C% confident that the confidence interval for a population proportion captures the population proportion.","tags":[]},{"id":356323,"external_key":"19.apst.0.1.3.14.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.14.2","label":"UNC-4.F.3","description":"UNC-4.F.3: In repeated random sampling with the same sample size, approximately C% of confidence intervals created will capture the population proportion.","tags":[]},{"id":356324,"external_key":"19.apst.0.1.3.14.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.14.3","label":"UNC-4.F.4","description":"UNC-4.F.4: Interpreting a confidence interval for a one-sample proportion should include a reference to the sample taken and details about the population it represents.","tags":[]}]},{"id":356325,"external_key":"19.apst.0.1.3.15","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.15","label":"UNC-4.G","description":"UNC-4.G: Justify a claim based on a confidence interval for a population proportion.","tags":[{"id":356326,"external_key":"19.apst.0.1.3.15.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.15.0","label":"UNC-4.G.1","description":"UNC-4.G.1: A confidence interval for a population proportion provides an interval of values that may provide sufficient evidence to support a particular claim in context.","tags":[]}]},{"id":356327,"external_key":"19.apst.0.1.3.16","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.16","label":"UNC-4.H","description":"UNC-4.H: Identify the relationships between sample size, width of a confidence interval, confidence level, and margin of error for a population proportion.","tags":[{"id":356328,"external_key":"19.apst.0.1.3.16.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.16.0","label":"UNC-4.H.1","description":"UNC-4.H.1: When all other things remain the same, the width of the confidence interval for a population proportion tends to decrease as the sample size increases. For a population proportion, the width of the interval is proportional to 1/√n.","tags":[]},{"id":356329,"external_key":"19.apst.0.1.3.16.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.16.1","label":"UNC-4.H.2","description":"UNC-4.H.2: For a given sample, the width of the confidence interval for a population proportion increases as the confidence level increases.","tags":[]},{"id":356330,"external_key":"19.apst.0.1.3.16.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.16.2","label":"UNC-4.H.3","description":"UNC-4.H.3: The width of a confidence interval for a population proportion is exactly twice the margin of error.","tags":[]}]},{"id":356331,"external_key":"19.apst.0.1.3.17","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.17","label":"UNC-4.I","description":"UNC-4.I: Identify an appropriate confidence interval procedure for a comparison of population proportions.","tags":[{"id":356332,"external_key":"19.apst.0.1.3.17.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.17.0","label":"UNC-4.I.1","description":"UNC-4.I.1: The appropriate confidence interval procedure for a two-sample comparison of proportions for one categorical variable is a two-sample z-interval for a difference between population proportions.","tags":[]}]},{"id":356333,"external_key":"19.apst.0.1.3.18","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.18","label":"UNC-4.J","description":"UNC-4.J: Verify the conditions for calculating confidence intervals for a difference between population proportions.","tags":[{"id":356334,"external_key":"19.apst.0.1.3.18.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.18.0","label":"UNC-4.J.1","description":"UNC-4.J.1: In order to calculate confidence intervals to estimate a difference between proportions, we must check for independence and that the sampling distribution is approximately normal- a. To check for independence- i. Data should be collected using random samples or a randomized experiment. ii. When sampling without replacement, check that n₁ ≤ 10%N₁ and n₂ ≤ 10%N₂. b. To check that sampling distribution of p-hat₁ - p-hat2 is approximately normal (shape). i. For categorical variables, check that n₁ · p-hat₁, n₁ · (1 - p-hat₁), n₂ · p-hat₂, and n₂ · (1 - p-hat₂) are all greater than or equal to some predetermined value, typically either 5 or 10.","tags":[]}]},{"id":356335,"external_key":"19.apst.0.1.3.19","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.19","label":"UNC-4.K","description":"UNC-4.K: Calculate an appropriate confidence interval for a comparison of population proportions.","tags":[{"id":356336,"external_key":"19.apst.0.1.3.19.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.19.0","label":"UNC-4.K.1","description":"UNC-4.K.1: For a comparison of proportions, the interval estimate is- (p-hat₁ - p-hat₂) ± z* ∙ √[((p-hat₁)(1 - p-hat₁))/n₁ + ((p-hat₂)(1 - p-hat₂))/n₂].","tags":[]}]},{"id":356337,"external_key":"19.apst.0.1.3.20","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.20","label":"UNC-4.L","description":"UNC-4.L: Calculate an interval estimate based on a confidence interval for a difference of proportions.","tags":[{"id":356338,"external_key":"19.apst.0.1.3.20.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.20.0","label":"UNC-4.L.1","description":"UNC-4.L.1: Confidence intervals for a difference in proportions can be used to calculate interval estimates with specified units.","tags":[]}]},{"id":356339,"external_key":"19.apst.0.1.3.21","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.21","label":"UNC-4.M","description":"UNC-4.M: Interpret a confidence interval for a difference of proportions.","tags":[{"id":356340,"external_key":"19.apst.0.1.3.21.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.21.0","label":"UNC-4.M.1","description":"UNC-4.M.1: In repeated random sampling with the same sample size, approximately C% of confidence intervals created will capture the difference in population proportions.","tags":[]},{"id":356341,"external_key":"19.apst.0.1.3.21.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.21.1","label":"UNC-4.M.2","description":"UNC-4.M.2: Interpreting a confidence interval for difference between population proportions should include a reference to the sample taken and details about the population it represents.","tags":[]}]},{"id":356342,"external_key":"19.apst.0.1.3.22","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.22","label":"UNC-4.N","description":"UNC-4.N: Justify a claim based on a confidence interval for a difference of proportions.","tags":[{"id":356343,"external_key":"19.apst.0.1.3.22.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.22.0","label":"UNC-4.N.1","description":"UNC-4.N.1: A confidence interval for difference in population proportions provides an interval of values that may provide sufficient evidence to support a particular claim in context.","tags":[]}]},{"id":356344,"external_key":"19.apst.0.1.3.23","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.23","label":"UNC-4.O","description":"UNC-4.O: Identify an appropriate confidence interval procedure for a population mean, including the mean difference between values in matched pairs.","tags":[{"id":356345,"external_key":"19.apst.0.1.3.23.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.23.0","label":"UNC-4.O.1","description":"UNC-4.O.1: Because sigma is typically not known for distributions of quantitative variables, the appropriate confidence interval procedure for estimating the population mean of one quantitative variable for one sample is a one-sample t-interval for a mean.","tags":[]},{"id":356346,"external_key":"19.apst.0.1.3.23.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.23.1","label":"UNC-4.O.2","description":"UNC-4.O.2: For one quantitative variable, X, that is normally distributed, the distribution of t = (x-bar - μ)/(s/√n) is a t-distribution with n - 1 degrees of freedom.","tags":[]},{"id":356347,"external_key":"19.apst.0.1.3.23.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.23.2","label":"UNC-4.O.3","description":"UNC-4.O.3: Matched pairs can be thought of as one sample of pairs. Once differences between pairs of values are found, inference for confidence intervals proceeds as for a population mean.","tags":[]}]},{"id":356348,"external_key":"19.apst.0.1.3.24","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.24","label":"UNC-4.P","description":"UNC-4.P: Verify the conditions for calculating confidence intervals for a population mean, including the mean difference between values in matched pairs.","tags":[{"id":356349,"external_key":"19.apst.0.1.3.24.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.24.0","label":"UNC-4.P.1","description":"UNC-4.P.1: In order to calculate confidence intervals to estimate a population mean, we must check for independence and that the sampling distribution is approximately normal-  a. To check for independence-  i. Data should be collected using a random sample or a randomized experiment.  ii. When sampling without replacement, check that n ≤ 10%N, where N is the size of the population. b. To check that the sampling distribution of x-bar is approximately normal (shape)-  i. If the observed distribution is skewed, n should be greater than 30.  ii. If the sample size is less than 30, the distribution of the sample data should be free from strong skewness and outliers.","tags":[]}]},{"id":356350,"external_key":"19.apst.0.1.3.25","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.25","label":"UNC-4.Q","description":"UNC-4.Q: Determine the margin of error for a given sample size for a one-sample t-interval.","tags":[{"id":356351,"external_key":"19.apst.0.1.3.25.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.25.0","label":"UNC-4.Q.1","description":"UNC-4.Q.1: The critical value t* with n - 1 degrees of freedom can be found using a table or computer-generated output.","tags":[]},{"id":356352,"external_key":"19.apst.0.1.3.25.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.25.1","label":"UNC-4.Q.2","description":"UNC-4.Q.2: The standard error for a sample mean is given by SE = s/√n, where s is the sample standard deviation.","tags":[]},{"id":356353,"external_key":"19.apst.0.1.3.25.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.25.2","label":"UNC-4.Q.3","description":"UNC-4.Q.3: For a one-sample t-interval for a mean, the margin of error is the critical value (t*) times the standard error (SE), which equals t* ∙ (s/√n).","tags":[]}]},{"id":356354,"external_key":"19.apst.0.1.3.26","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.26","label":"UNC-4.R","description":"UNC-4.R: Calculate an appropriate confidence interval for a population mean, including the mean difference between values in matched pairs.","tags":[{"id":356355,"external_key":"19.apst.0.1.3.26.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.26.0","label":"UNC-4.R.1","description":"UNC-4.R.1: The point estimate for a population mean is the sample mean, x-bar.","tags":[]},{"id":356356,"external_key":"19.apst.0.1.3.26.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.26.1","label":"UNC-4.R.2","description":"UNC-4.R.2: For the population mean for one sample with unknown population standard deviation, the confidence interval is x-bar ± t* ∙ (s/√n).","tags":[]}]},{"id":356357,"external_key":"19.apst.0.1.3.27","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.27","label":"UNC-4.S","description":"UNC-4.S: Interpret a confidence interval for a population mean, including the mean difference between values in matched pairs.","tags":[{"id":356358,"external_key":"19.apst.0.1.3.27.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.27.0","label":"UNC-4.S.1","description":"UNC-4.S.1: A confidence interval for a population mean either contains the population mean or it does not, because each interval is based on data from a random sample, which varies from sample to sample.","tags":[]},{"id":356359,"external_key":"19.apst.0.1.3.27.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.27.1","label":"UNC-4.S.2","description":"UNC-4.S.2: We are C% confident that the confidence interval for a population mean captures the population mean.","tags":[]},{"id":356360,"external_key":"19.apst.0.1.3.27.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.27.2","label":"UNC-4.S.3","description":"UNC-4.S.3: An interpretation of a confidence interval for a population mean includes a reference to the sample taken and details about the population it represents.","tags":[]}]},{"id":356361,"external_key":"19.apst.0.1.3.28","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.28","label":"UNC-4.T","description":"UNC-4.T: Justify a claim based on a confidence interval for a population mean, including the mean difference between values in matched pairs.","tags":[{"id":356362,"external_key":"19.apst.0.1.3.28.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.28.0","label":"UNC-4.T.1","description":"UNC-4.T.1: A confidence interval for a population mean provides an interval of values that may provide sufficient evidence to support a particular claim in context.","tags":[]}]},{"id":356363,"external_key":"19.apst.0.1.3.29","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.29","label":"UNC-4.U","description":"UNC-4.U: Identify the relationships between sample size, width of a confidence interval, confidence level, and margin of error for a population mean.","tags":[{"id":356364,"external_key":"19.apst.0.1.3.29.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.29.0","label":"UNC-4.U.1","description":"UNC-4.U.1: When all other things remain the same, the width of a confidence interval for a population mean tends to decrease as the sample size increases.","tags":[]},{"id":356365,"external_key":"19.apst.0.1.3.29.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.29.1","label":"UNC-4.U.2","description":"UNC-4.U.2: For a single mean, the width of the interval is proportional to 1/√n.","tags":[]},{"id":356366,"external_key":"19.apst.0.1.3.29.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.29.2","label":"UNC-4.U.3","description":"UNC-4.U.3: For a given sample, the width of the confidence interval for a population mean increases as the confidence level increases.","tags":[]}]},{"id":356367,"external_key":"19.apst.0.1.3.30","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.30","label":"UNC-4.V","description":"UNC-4.V: Identify an appropriate confidence interval procedure for a difference of two population means.","tags":[{"id":356368,"external_key":"19.apst.0.1.3.30.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.30.0","label":"UNC-4.V.1","description":"UNC-4.V.1: Consider a simple random sample from population 1 of size n₁, mean µ₁, and standard deviation sigma₁ and a second simple random sample from population 2 of size n₂, mean µ₂, and standard deviation sigma₂. If the distributions of populations 1 and 2 are normal or if both n₁ and n₂ are greater than 30, then the sampling distribution of the difference of means, x-bar₁ - x-bar₂ is also normal. The mean for the sampling distribution of x-bar₁ - x-bar₂ is µ₁ - µ₂. The standard deviation of x-bar₁ - x-bar₂ is √[((sigma₁)²/n₁) + ((sigma₂)²/n₂)].","tags":[]},{"id":356369,"external_key":"19.apst.0.1.3.30.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.30.1","label":"UNC-4.V.2","description":"UNC-4.V.2: The appropriate confidence interval procedure for one quantitative variable for two independent samples is a two-sample t-interval for a difference between population means.","tags":[]}]},{"id":356370,"external_key":"19.apst.0.1.3.31","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.31","label":"UNC-4.W","description":"UNC-4.W: Verify the conditions to calculate confidence intervals for the difference of two population means.","tags":[{"id":356371,"external_key":"19.apst.0.1.3.31.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.31.0","label":"UNC-4.W.1","description":"UNC-4.W.1: In order to calculate confidence intervals to estimate a difference of population means, we must check for independence and that the sampling distribution is approximately normal- a. To check for independence- i. Data should be collected using two independent, random samples or a randomized experiment. ii. When sampling without replacement, check that n₁ ≤ 10%N₁ and n₂ ≤ 10%N₂. b. To check that the sampling distribution of (x-bar₁ - x-bar₂) should be approximately normal (shape)- i. If the observed distributions are skewed, both n₁ and n₂ should be greater than 30.","tags":[]}]},{"id":356372,"external_key":"19.apst.0.1.3.32","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.32","label":"UNC-4.X","description":"UNC-4.X: Determine the margin of error for the difference of two population means.","tags":[{"id":356373,"external_key":"19.apst.0.1.3.32.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.32.0","label":"UNC-4.X.1","description":"UNC-4.X.1: For the difference of two sample means, the margin of error is the critical value (t*) times the standard error (SE) of the difference of two means.","tags":[]},{"id":356374,"external_key":"19.apst.0.1.3.32.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.32.1","label":"UNC-4.X.2","description":"UNC-4.X.2: The standard error for the difference in two sample means with sample standard deviations, s₁ and s₂, is √[((s₁)2/n₁) + ((s₂)2/n₂)].","tags":[]}]},{"id":356375,"external_key":"19.apst.0.1.3.33","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.33","label":"UNC-4.Y","description":"UNC-4.Y: Calculate an appropriate confidence interval for a difference of two population means.","tags":[{"id":356376,"external_key":"19.apst.0.1.3.33.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.33.0","label":"UNC-4.Y.1","description":"UNC-4.Y.1: The point estimate for the difference of two population means is the difference in sample means, x-bar₁ - x-bar₂.","tags":[]},{"id":356377,"external_key":"19.apst.0.1.3.33.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.33.1","label":"UNC-4.Y.2","description":"UNC-4.Y.2: For a difference of two population means where the population standard deviations are not known, the confidence interval is (x-bar₁ - x-bar₂) ± t* ∙ √[((s₁)2/n₁) + ((s₂)2/n₂)] where ±t* are the critical values for the central C% of a t-distribution with appropriate degrees of freedom that can be found using technology.","tags":[]}]},{"id":356378,"external_key":"19.apst.0.1.3.34","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.34","label":"UNC-4.Z","description":"UNC-4.Z: Interpret a confidence interval for a difference of population means.","tags":[{"id":356379,"external_key":"19.apst.0.1.3.34.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.34.0","label":"UNC-4.Z.1","description":"UNC-4.Z.1: In repeated random sampling with the same sample size, approximately C% of confidence intervals created will capture the difference of population means.","tags":[]},{"id":356380,"external_key":"19.apst.0.1.3.34.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.3.34.1","label":"UNC-4.Z.2","description":"UNC-4.Z.2: An interpretation for a confidence interval for the difference of two population means should include a reference to the samples taken and details about the populations they represent.","tags":[]}]}]},{"id":356381,"external_key":"19.apst.0.1.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4","label":"UNC-5","description":"UNC-5: Probabilities of Type I and Type II errors influence inference.","tags":[{"id":356382,"external_key":"19.apst.0.1.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.0","label":"UNC-5.A","description":"UNC-5.A: Identify Type I and Type II errors.","tags":[{"id":356383,"external_key":"19.apst.0.1.4.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.0.0","label":"UNC-5.A.1","description":"UNC-5.A.1: A Type I error occurs when the null hypothesis is true and is rejected (false positive).","tags":[]},{"id":356384,"external_key":"19.apst.0.1.4.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.0.1","label":"UNC-5.A.2","description":"UNC-5.A.2: A Type II error occurs when the null hypothesis is false and is not rejected (false negative).","tags":[]}]},{"id":356385,"external_key":"19.apst.0.1.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.1","label":"UNC-5.B","description":"UNC-5.B: Calculate the probability of Type I and Type II errors.","tags":[{"id":356386,"external_key":"19.apst.0.1.4.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.1.0","label":"UNC-5.B.1","description":"UNC-5.B.1: The significance level, α, is the probability of making a Type I error, if the null hypothesis is true.","tags":[]},{"id":356387,"external_key":"19.apst.0.1.4.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.1.1","label":"UNC-5.B.2","description":"UNC-5.B.2: The power of a test is the probability that a test will correctly reject a false null hypothesis.","tags":[]},{"id":356388,"external_key":"19.apst.0.1.4.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.1.2","label":"UNC-5.B.3","description":"UNC-5.B.3: The probability of making a Type II error=1-Power.","tags":[]}]},{"id":356389,"external_key":"19.apst.0.1.4.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.2","label":"UNC-5.C","description":"UNC-5.C: Identify factors that affect the probability of errors in significance testing.","tags":[{"id":356390,"external_key":"19.apst.0.1.4.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.2.0","label":"UNC-5.C.1","description":"UNC-5.C.1: The probability of a Type II error decreases when any of the following occurs, provided the others do not change- a. sample size(s) increases. b. significance level (α) of a test increases. c. standard error decreases. d. true parameter value is farther from the null.","tags":[]}]},{"id":356391,"external_key":"19.apst.0.1.4.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.3","label":"UNC-5.D","description":"UNC-5.D: Interpret Type I and Type II errors.","tags":[{"id":356392,"external_key":"19.apst.0.1.4.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.3.0","label":"UNC-5.D.1","description":"UNC-5.D.1: Whether a Type I or a Type II error is more consequential depends upon the situation.","tags":[]},{"id":356393,"external_key":"19.apst.0.1.4.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.1.4.3.1","label":"UNC-5.D.2","description":"UNC-5.D.2: Since the significance level, α, is the probability of a Type I error, the consequences of a Type I error influence decisions about a significance level.","tags":[]}]}]}]},{"id":356394,"external_key":"19.apst.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2","label":"VAR","description":"VAR: Variation and Distribution","tags":[{"id":356395,"external_key":"19.apst.0.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0","label":"VAR-1","description":"VAR-1: Given that variation may be random or not, conclusions are uncertain.","tags":[{"id":356396,"external_key":"19.apst.0.2.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.0","label":"VAR-1.A","description":"VAR-1.A: Identify questions to be answered, based on variation in one-variable data.","tags":[{"id":356397,"external_key":"19.apst.0.2.0.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.0.0","label":"VAR-1.A.1","description":"VAR-1.A.1: Numbers may convey meaningful information, when placed in context.","tags":[]}]},{"id":356398,"external_key":"19.apst.0.2.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.1","label":"VAR-1.B","description":"VAR-1.B: Identify variables in a set of data.","tags":[{"id":356399,"external_key":"19.apst.0.2.0.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.1.0","label":"VAR-1.B.1","description":"VAR-1.B.1: A variable is a characteristic that changes from one individual to another.","tags":[]}]},{"id":356400,"external_key":"19.apst.0.2.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.2","label":"VAR-1.C","description":"VAR-1.C: Classify types of variables.","tags":[{"id":356401,"external_key":"19.apst.0.2.0.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.2.0","label":"VAR-1.C.1","description":"VAR-1.C.1: A categorical variable takes on values that are category names or group labels.","tags":[]},{"id":356402,"external_key":"19.apst.0.2.0.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.2.1","label":"VAR-1.C.2","description":"VAR-1.C.2: A quantitative variable is one that takes on numerical values for a measured or counted quantity.","tags":[]}]},{"id":356403,"external_key":"19.apst.0.2.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.3","label":"VAR-1.D","description":"VAR-1.D: Identify questions to be answered about possible relationships in data.","tags":[{"id":356404,"external_key":"19.apst.0.2.0.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.3.0","label":"VAR-1.D.1","description":"VAR-1.D.1: Apparent patterns and associations in data may be random or not.","tags":[]}]},{"id":356405,"external_key":"19.apst.0.2.0.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.4","label":"VAR-1.E","description":"VAR-1.E: Identify questions to be answered about data collection methods.","tags":[{"id":356406,"external_key":"19.apst.0.2.0.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.4.0","label":"VAR-1.E.1","description":"VAR-1.E.1: Methods for data collection that do not rely on chance result in untrustworthy conclusions.","tags":[]}]},{"id":356407,"external_key":"19.apst.0.2.0.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.5","label":"VAR-1.F","description":"VAR-1.F: Identify questions suggested by patterns in data.","tags":[{"id":356408,"external_key":"19.apst.0.2.0.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.5.0","label":"VAR-1.F.1","description":"VAR-1.F.1: Patterns in data do not necessarily mean that variation is not random.","tags":[]}]},{"id":356409,"external_key":"19.apst.0.2.0.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.6","label":"VAR-1.G","description":"VAR-1.G: Identify questions suggested by variation in statistics for samples collected from the same population.","tags":[{"id":356410,"external_key":"19.apst.0.2.0.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.6.0","label":"VAR-1.G.1","description":"VAR-1.G.1: Variation in statistics for samples taken from the same population may be random or not.","tags":[]}]},{"id":356411,"external_key":"19.apst.0.2.0.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.7","label":"VAR-1.H","description":"VAR-1.H: Identify questions suggested by variation in the shapes of distributions of samples taken from the same population.","tags":[{"id":356412,"external_key":"19.apst.0.2.0.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.7.0","label":"VAR-1.H.1","description":"VAR-1.H.1: Variation in shapes of data distributions may be random or not.","tags":[]}]},{"id":356413,"external_key":"19.apst.0.2.0.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.8","label":"VAR-1.I","description":"VAR-1.I: Identify questions suggested by probabilities of errors in statistical inference.","tags":[{"id":356414,"external_key":"19.apst.0.2.0.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.8.0","label":"VAR-1.I.1","description":"VAR-1.I.1: Random variation may result in errors in statistical inference.","tags":[]}]},{"id":356415,"external_key":"19.apst.0.2.0.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.9","label":"VAR-1.J","description":"VAR-1.J: Identify questions suggested by variation between observed and expected counts in categorical data.","tags":[{"id":356416,"external_key":"19.apst.0.2.0.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.9.0","label":"VAR-1.J.1","description":"VAR-1.J.1: Variation between what we find and what we expect to find may be random or not.","tags":[]}]},{"id":356417,"external_key":"19.apst.0.2.0.10","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.10","label":"VAR-1.K","description":"VAR-1.K: Identify questions suggested by variation in scatter plots.","tags":[{"id":356418,"external_key":"19.apst.0.2.0.10.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.0.10.0","label":"VAR-1.K.1","description":"VAR-1.K.1: Variation in points' positions relative to a theoretical line may be random or non-random.","tags":[]}]}]},{"id":356419,"external_key":"19.apst.0.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1","label":"VAR-2","description":"VAR-2: The normal distribution can be used to represent some population distributions.","tags":[{"id":356420,"external_key":"19.apst.0.2.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.0","label":"VAR-2.A","description":"VAR-2.A: Compare a data distribution to the normal distribution model.","tags":[{"id":356421,"external_key":"19.apst.0.2.1.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.0.0","label":"VAR-2.A.1","description":"VAR-2.A.1: A parameter is a numerical summary of a population.","tags":[]},{"id":356422,"external_key":"19.apst.0.2.1.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.0.1","label":"VAR-2.A.2","description":"VAR-2.A.2: Some sets of data may be described as approximately normally distributed. A normal curve is mound-shaped and symmetric. The parameters of a normal distribution are the population mean, µ, and the population standard deviation, sigma.","tags":[]},{"id":356423,"external_key":"19.apst.0.2.1.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.0.2","label":"VAR-2.A.3","description":"VAR-2.A.3: For a normal distribution, approximately 68% of the observations are within 1 standard deviation of the mean, approximately 95% of observations are within 2 standard deviations of the mean, and approximately 99.7% of observations are within 3 standard deviations of the mean. This is called the empirical rule.","tags":[]},{"id":356424,"external_key":"19.apst.0.2.1.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.0.3","label":"VAR-2.A.4","description":"VAR-2.A.4: Many variables can be modeled by a normal distribution.","tags":[]}]},{"id":356425,"external_key":"19.apst.0.2.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.1","label":"VAR-2.B","description":"VAR-2.B: Determine proportions and percentiles from a normal distribution.","tags":[{"id":356426,"external_key":"19.apst.0.2.1.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.1.0","label":"VAR-2.B.1","description":"VAR-2.B.1: A standardized score for a particular data value is calculated as (data value - mean)/(standard deviation), and measures the number of standard deviations a data value falls above or below the mean.","tags":[]},{"id":356427,"external_key":"19.apst.0.2.1.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.1.1","label":"VAR-2.B.2","description":"VAR-2.B.2: One example of a standardized score is a z-score, which is calculated as z-score = (x_i - μ)/sigma. A z-score measures how many standard deviations a data value is from the mean.","tags":[]},{"id":356428,"external_key":"19.apst.0.2.1.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.1.2","label":"VAR-2.B.3","description":"VAR-2.B.3: Technology, such as a calculator, a standard normal table, or computer-generated output, can be used to find the proportion of a data values located on a given interval of a normally distributed random variable.","tags":[]},{"id":356429,"external_key":"19.apst.0.2.1.1.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.1.3","label":"VAR-2.B.4","description":"VAR-2.B.4: Given the area of a region under the graph of the normal distribution curve, it is possible to use technology, such as a calculator, a standard normal table, or computer-generated output, to estimate parameters for some populations.","tags":[]}]},{"id":356430,"external_key":"19.apst.0.2.1.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.2","label":"VAR-2.C","description":"VAR-2.C: Compare measures of relative position in data sets.","tags":[{"id":356431,"external_key":"19.apst.0.2.1.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.1.2.0","label":"VAR-2.C.1","description":"VAR-2.C.1: Percentiles and z-scores may be used to compare relative positions of points within a data set or between data sets.","tags":[]}]}]},{"id":356432,"external_key":"19.apst.0.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2","label":"VAR-3","description":"VAR-3: Well-designed experiments can establish evidence of causal relationships.","tags":[{"id":356433,"external_key":"19.apst.0.2.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.0","label":"VAR-3.A","description":"VAR-3.A: Identify the components of an experiment.","tags":[{"id":356434,"external_key":"19.apst.0.2.2.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.0.0","label":"VAR-3.A.1","description":"VAR-3.A.1: The experimental units are the individuals (which may be people or other objects of study) that are assigned treatments. When experimental units consist of people, they are sometimes referred to as participants or subjects.","tags":[]},{"id":356435,"external_key":"19.apst.0.2.2.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.0.1","label":"VAR-3.A.2","description":"VAR-3.A.2: An explanatory variable (or factor) in an experiment is a variable whose levels are manipulated intentionally. The levels or combination of levels of the explanatory variable(s) are called treatments.","tags":[]},{"id":356436,"external_key":"19.apst.0.2.2.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.0.2","label":"VAR-3.A.3","description":"VAR-3.A.3: A response variable in an experiment is an outcome from the experimental units that is measured after the treatments have been administered.","tags":[]},{"id":356437,"external_key":"19.apst.0.2.2.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.0.3","label":"VAR-3.A.4","description":"VAR-3.A.4: A confounding variable in an experiment is a variable that is related to the explanatory variable and influences the response variable and may create a false perception of association between the two.","tags":[]}]},{"id":356438,"external_key":"19.apst.0.2.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.1","label":"VAR-3.B","description":"VAR-3.B: Describe elements of a well-designed experiment.","tags":[{"id":356439,"external_key":"19.apst.0.2.2.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.1.0","label":"VAR-3.B.1","description":"VAR-3.B.1: A well-designed experiment should include the following- a. Comparisons of at least two treatment groups, one of which could be a control group. b. Random assignment/allocation of treatments to experimental units. c. Replication (more than one experimental unit in each treatment group). d. Control of potential confounding variables where appropriate.","tags":[]}]},{"id":356440,"external_key":"19.apst.0.2.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2","label":"VAR-3.C","description":"VAR-3.C: Compare experimental designs and methods.","tags":[{"id":356441,"external_key":"19.apst.0.2.2.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.0","label":"VAR-3.C.1","description":"VAR-3.C.1: In a completely randomized design, treatments are assigned to experimental units completely at random. Random assignment tends to balance the effects of uncontrolled (confounding) variables so that differences in responses can be attributed to the treatments.","tags":[]},{"id":356442,"external_key":"19.apst.0.2.2.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.1","label":"VAR-3.C.2","description":"VAR-3.C.2: Methods for randomly assigning treatments to experimental units in a completely randomized design include using a random number generator, a table of random values, drawing chips without replacement, etc.","tags":[]},{"id":356443,"external_key":"19.apst.0.2.2.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.2","label":"VAR-3.C.3","description":"VAR-3.C.3: In a single-blind experiment, subjects do not know which treatment they are receiving, but members of the research team do, or vice versa.","tags":[]},{"id":356444,"external_key":"19.apst.0.2.2.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.3","label":"VAR-3.C.4","description":"VAR-3.C.4: In a double-blind experiment neither the subjects nor the members of the research team who interact with them know which treatment a subject is receiving.","tags":[]},{"id":356445,"external_key":"19.apst.0.2.2.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.4","label":"VAR-3.C.5","description":"VAR-3.C.5: A control group is a collection of experimental units either not given a treatment of interest or given a treatment with an inactive substance (placebo) in order to determine if the treatment of interest has an effect.","tags":[]},{"id":356446,"external_key":"19.apst.0.2.2.2.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.5","label":"VAR-3.C.6","description":"VAR-3.C.6: The placebo effect occurs when experimental units have a response to a placebo.","tags":[]},{"id":356447,"external_key":"19.apst.0.2.2.2.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.6","label":"VAR-3.C.7","description":"VAR-3.C.7: For randomized complete block designs, treatments are assigned completely at random within each block.","tags":[]},{"id":356448,"external_key":"19.apst.0.2.2.2.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.7","label":"VAR-3.C.8","description":"VAR-3.C.8: Blocking ensures that at the beginning of the experiment the units within each block are similar to each other with respect to at least one blocking variable. A randomized block design helps to separate natural variability from differences due to the blocking variable.","tags":[]},{"id":356449,"external_key":"19.apst.0.2.2.2.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.2.8","label":"VAR-3.C.9","description":"VAR-3.C.9: A matched pairs design is a special case of a randomized block design. Using a blocking variable, subjects (whether they are people or not) are arranged in pairs matched on relevant factors. Matched pairs may be formed naturally or by the experimenter. Every pair receives both treatments by randomly assigning one treatment to one member of the pair and subsequently assigning the remaining treatment to the second member of the pair. Alternately, each subject may get both treatments.","tags":[]}]},{"id":356450,"external_key":"19.apst.0.2.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.3","label":"VAR-3.D","description":"VAR-3.D: Explain why a particular experimental design is appropriate.","tags":[{"id":356451,"external_key":"19.apst.0.2.2.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.3.0","label":"VAR-3.D.1","description":"VAR-3.D.1: There are advantages and disadvantages for each experimental design depending on the question of interest, the resources available, and the nature of the experimental units.","tags":[]}]},{"id":356452,"external_key":"19.apst.0.2.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.4","label":"VAR-3.E","description":"VAR-3.E: Interpret the results of a well-designed experiment.","tags":[{"id":356453,"external_key":"19.apst.0.2.2.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.4.0","label":"VAR-3.E.1","description":"VAR-3.E.1: Statistical inference attributes conclusions based on data to the distribution from which the data were collected.","tags":[]},{"id":356454,"external_key":"19.apst.0.2.2.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.4.1","label":"VAR-3.E.2","description":"VAR-3.E.2: Random assignment of treatments to experimental units allows researchers to conclude that some observed changes are so large as to be unlikely to have occurred by chance. Such changes are said to be statistically significant.","tags":[]},{"id":356455,"external_key":"19.apst.0.2.2.4.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.4.2","label":"VAR-3.E.3","description":"VAR-3.E.3: Statistically significant differences between or among experimental treatment groups are evidence that the treatments caused the effect.","tags":[]},{"id":356456,"external_key":"19.apst.0.2.2.4.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.2.4.3","label":"VAR-3.E.4","description":"VAR-3.E.4: If the experimental units used in an experiment are representative of some larger group of units, the results of an experiment can be generalized to the larger group. Random selection of experimental units gives a better chance that the units will be representative.","tags":[]}]}]},{"id":356457,"external_key":"19.apst.0.2.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3","label":"VAR-4","description":"VAR-4: The likelihood of a random event can be quantified.","tags":[{"id":356458,"external_key":"19.apst.0.2.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.0","label":"VAR-4.A","description":"VAR-4.A: Calculate probabilities for events and their complements.","tags":[{"id":356459,"external_key":"19.apst.0.2.3.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.0.0","label":"VAR-4.A.1","description":"VAR-4.A.1: The sample space of a random process is the set of all possible non-overlapping outcomes.","tags":[]},{"id":356460,"external_key":"19.apst.0.2.3.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.0.1","label":"VAR-4.A.2","description":"VAR-4.A.2: If all outcomes in the sample space are equally likely, then the probability an event E will occur is defined as the fraction- (number of outcomes in event E)/(total number of outcomes in the sample space)","tags":[]},{"id":356461,"external_key":"19.apst.0.2.3.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.0.2","label":"VAR-4.A.3","description":"VAR-4.A.3: The probability of an event is a number between 0 and 1, inclusive.","tags":[]},{"id":356462,"external_key":"19.apst.0.2.3.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.0.3","label":"VAR-4.A.4","description":"VAR-4.A.4: The probability of the complement of an event E, E' or E^C, (i.e. not E) is equal to 1 - P(E).","tags":[]}]},{"id":356463,"external_key":"19.apst.0.2.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.1","label":"VAR-4.B","description":"VAR-4.B: Interpret probabilities for events.","tags":[{"id":356464,"external_key":"19.apst.0.2.3.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.1.0","label":"VAR-4.B.1","description":"VAR-4.B.1: Probabilities of events in repeatable situations can be interpreted as the relative frequency with which the event will occur in the long run.","tags":[]}]},{"id":356465,"external_key":"19.apst.0.2.3.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.2","label":"VAR-4.C","description":"VAR-4.C: Explain why two events are (or are not) mutually exclusive.","tags":[{"id":356466,"external_key":"19.apst.0.2.3.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.2.0","label":"VAR-4.C.1","description":"VAR-4.C.1: The probability that events A and B both will occur, sometimes called the joint probability, is the probability of the intersection of A and B, denoted P(A∩B).","tags":[]},{"id":356467,"external_key":"19.apst.0.2.3.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.2.1","label":"VAR-4.C.2","description":"VAR-4.C.2: Two events are mutually exclusive or disjoint if they cannot occur at the same time. So P(A∩B) = 0.","tags":[]}]},{"id":356468,"external_key":"19.apst.0.2.3.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.3","label":"VAR-4.D","description":"VAR-4.D: Calculate conditional probabilities.","tags":[{"id":356469,"external_key":"19.apst.0.2.3.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.3.0","label":"VAR-4.D.1","description":"VAR-4.D.1: The probability that event A will occur given that event B has occurred is called a conditional probability and denoted P(A|B) = [P(A∩B)]/[P(B)].","tags":[]},{"id":356470,"external_key":"19.apst.0.2.3.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.3.1","label":"VAR-4.D.2","description":"VAR-4.D.2: The multiplication rule states that the probability that events A and B both will occur is equal to the probability that event A will occur multiplied by the probability that event B will occur, given that A has occurred. This is denoted P(A∩B) = P(A)∙P(B|A).","tags":[]}]},{"id":356471,"external_key":"19.apst.0.2.3.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.4","label":"VAR-4.E","description":"VAR-4.E: Calculate probabilities for independent events and for the union of two events.","tags":[{"id":356472,"external_key":"19.apst.0.2.3.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.4.0","label":"VAR-4.E.1","description":"VAR-4.E.1: Events A and B are independent if and only if knowing whether event A has occurred (or will occur) does not change the probability that event B will occur.","tags":[]},{"id":356473,"external_key":"19.apst.0.2.3.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.4.1","label":"VAR-4.E.2","description":"VAR-4.E.2: If and only if events A and B are independent, then P(A|B) = P(A) , P(B|A) = P(B), and P(A∩B) = P(A)∙P(B).","tags":[]},{"id":356474,"external_key":"19.apst.0.2.3.4.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.4.2","label":"VAR-4.E.3","description":"VAR-4.E.3: The probability that event A or event B (or both) will occur is the probability of the union of A and B, denoted P(A ᴜ B).","tags":[]},{"id":356475,"external_key":"19.apst.0.2.3.4.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.3.4.3","label":"VAR-4.E.4","description":"VAR-4.E.4: The addition rule states that the probability that event A or event B or both will occur is equal to the probability that event A will occur plus the probability that event B will occur minus the probability that both events A and B will occur. This is denoted P(A ᴜ B) = P(A) + P(B) - P(A∩B).","tags":[]}]}]},{"id":356476,"external_key":"19.apst.0.2.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4","label":"VAR-5","description":"VAR-5: Probability distributions may be used to model variation in populations.","tags":[{"id":356477,"external_key":"19.apst.0.2.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.0","label":"VAR-5.A","description":"VAR-5.A: Represent the probability distribution for a discrete random variable.","tags":[{"id":356478,"external_key":"19.apst.0.2.4.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.0.0","label":"VAR-5.A.1","description":"VAR-5.A.1: The values of a random variable are the numerical outcomes of random behavior.","tags":[]},{"id":356479,"external_key":"19.apst.0.2.4.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.0.1","label":"VAR-5.A.2","description":"VAR-5.A.2: A discrete random variable is a variable that can only take a countable number of values. Each value has a probability associated with it. The sum of the probabilities over all of the possible values must be 1.","tags":[]},{"id":356480,"external_key":"19.apst.0.2.4.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.0.2","label":"VAR-5.A.3","description":"VAR-5.A.3: A probability distribution can be represented as a graph, table, or function showing the probabilities associated with values of a random variable.","tags":[]},{"id":356481,"external_key":"19.apst.0.2.4.0.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.0.3","label":"VAR-5.A.4","description":"VAR-5.A.4: A cumulative probability distribution can be represented as a table or function showing the probability of being less than or equal to each value of the random variable.","tags":[]}]},{"id":356482,"external_key":"19.apst.0.2.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.1","label":"VAR-5.B","description":"VAR-5.B: Interpret a probability distribution.","tags":[{"id":356483,"external_key":"19.apst.0.2.4.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.1.0","label":"VAR-5.B.1","description":"VAR-5.B.1: An interpretation of a probability distribution provides information about the shape, center, and spread of a population and allows one to make conclusions about the population of interest.","tags":[]}]},{"id":356484,"external_key":"19.apst.0.2.4.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.2","label":"VAR-5.C","description":"VAR-5.C: Calculate parameters for a discrete random variable.","tags":[{"id":356485,"external_key":"19.apst.0.2.4.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.2.0","label":"VAR-5.C.1","description":"VAR-5.C.1: A numerical value measuring a characteristic of a population or the distribution of a random variable is known as a parameter, which is a single, fixed value.","tags":[]},{"id":356486,"external_key":"19.apst.0.2.4.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.2.1","label":"VAR-5.C.2","description":"VAR-5.C.2: The mean, or expected value, for a discrete random variable X is μ_x = ∑[x ∙ P(x)].","tags":[]},{"id":356487,"external_key":"19.apst.0.2.4.2.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.2.2","label":"VAR-5.C.3","description":"VAR-5.C.3: The standard deviation for a discrete random variable X is sigma_x = √[(x - µ_x)²∙P(x)], or √[∑[(x_i - µ_x)²∙p_i]].","tags":[]}]},{"id":356488,"external_key":"19.apst.0.2.4.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.3","label":"VAR-5.D","description":"VAR-5.D: Interpret parameters for a discrete random variable.","tags":[{"id":356489,"external_key":"19.apst.0.2.4.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.3.0","label":"VAR-5.D.1","description":"VAR-5.D.1: Parameters for a discrete random variable should be interpreted using appropriate units and within the context of a specific population.","tags":[]}]},{"id":356490,"external_key":"19.apst.0.2.4.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.4","label":"VAR-5.E","description":"VAR-5.E: Calculate parameters for linear combinations of random variables.","tags":[{"id":356491,"external_key":"19.apst.0.2.4.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.4.0","label":"VAR-5.E.1","description":"VAR-5.E.1: For random variables X and Y and real numbers a and b, the mean of aX + bY is a∙µ_x + b∙µ_y.","tags":[]},{"id":356492,"external_key":"19.apst.0.2.4.4.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.4.1","label":"VAR-5.E.2","description":"VAR-5.E.2: Two random variables are independent if knowing information about one of them does not change the probability distribution of the other.","tags":[]},{"id":356493,"external_key":"19.apst.0.2.4.4.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.4.2","label":"VAR-5.E.3","description":"VAR-5.E.3: For independent random variables X and Y and real numbers a and b, the mean of aX + bY is a∙µ_x + b∙µ_y, and the variance of a²(sigma²_x) + b²(sigma²_y).","tags":[]}]},{"id":356494,"external_key":"19.apst.0.2.4.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.5","label":"VAR-5.F","description":"VAR-5.F: Describe the effects of linear transformations of parameters of random variables.","tags":[{"id":356495,"external_key":"19.apst.0.2.4.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.4.5.0","label":"VAR-5.F.1","description":"VAR-5.F.1: For Y=a+bX, the probability distribution of the transformed random variable, Y, has the same shape as the probability distribution for X, so long as a>0 and b>0. The mean of Y is µ_y = a + b∙µ_x. The standard deviation of sigma_y = |b|∙ sigma_x.","tags":[]}]}]},{"id":356496,"external_key":"19.apst.0.2.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5","label":"VAR-6","description":"VAR-6: The normal distribution may be used to model variation.","tags":[{"id":356497,"external_key":"19.apst.0.2.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.0","label":"VAR-6.A","description":"VAR-6.A: Calculate the probability that a particular value lies in a given interval of a normal distribution.","tags":[{"id":356498,"external_key":"19.apst.0.2.5.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.0.0","label":"VAR-6.A.1","description":"VAR-6.A.1: A continuous random variable is a variable that can take on any value within a specified domain. Every interval within the domain has a probability associated with it.","tags":[]},{"id":356499,"external_key":"19.apst.0.2.5.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.0.1","label":"VAR-6.A.2","description":"VAR-6.A.2: A continuous random variable with a normal distribution is commonly used to describe populations. The distribution of a normal random variable can be described by a normal, or \"bell-shaped,\" curve.","tags":[]},{"id":356500,"external_key":"19.apst.0.2.5.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.0.2","label":"VAR-6.A.3","description":"VAR-6.A.3: The area under a normal curve over a given interval represents the probability that a particular value lies in that interval.","tags":[]}]},{"id":356501,"external_key":"19.apst.0.2.5.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.1","label":"VAR-6.B","description":"VAR-6.B: Determine the interval associated with a given area in a normal distribution.","tags":[{"id":356502,"external_key":"19.apst.0.2.5.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.1.0","label":"VAR-6.B.1","description":"VAR-6.B.1: The boundaries of an interval associated with a given area in a normal distribution can be determined using z-scores or technology, such as a calculator, a standard normal table, or computer generated output.","tags":[]},{"id":356503,"external_key":"19.apst.0.2.5.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.1.1","label":"VAR-6.B.2","description":"VAR-6.B.2: Intervals associated with a given area in a normal distribution can be determined by assigning appropriate inequalities to the boundaries of the intervals-  a. P(X < x_a) = p/100 means that the lowest p% of values lie to the left of x_a.  b. P(x_a < X < x_b) = p/100 means that p% of values lie between x_a and x_b.  c. P(X > x_b) = p/100 means that the highest p% of values lie to the right of x_b.  d. To determine the most extreme p% of values requires dividing the area associated with p% into two equal areas on either extreme of the distribution- P(X < x_a) = ½(p/100) and P(X > x_b) = ½(p/100) means that half of the p% most extreme values lie to the left of x_a and half of the p% most extreme values lie to the right of x_b.","tags":[]}]},{"id":356504,"external_key":"19.apst.0.2.5.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.2","label":"VAR-6.C","description":"VAR-6.C: Determine the appropriateness of using the normal distribution to approximate probabilities for unknown distributions.","tags":[{"id":356505,"external_key":"19.apst.0.2.5.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.2.0","label":"VAR-6.C.1","description":"VAR-6.C.1: Normal distributions are symmetrical and \"bell-shaped.\" As a result, normal distributions can be used to approximate distributions with similar characteristics.","tags":[]}]},{"id":356506,"external_key":"19.apst.0.2.5.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.3","label":"VAR-6.D","description":"VAR-6.D: Identify the null and alternative hypotheses for a population proportion.","tags":[{"id":356507,"external_key":"19.apst.0.2.5.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.3.0","label":"VAR-6.D.1","description":"VAR-6.D.1: The null hypothesis is the situation that is assumed to be correct unless evidence suggests otherwise, and the alternative hypothesis is the situation for which evidence is being collected.","tags":[]},{"id":356508,"external_key":"19.apst.0.2.5.3.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.3.1","label":"VAR-6.D.2","description":"VAR-6.D.2: For hypotheses about parameters, the null hypothesis contains an equality reference (=, ≥, or ≤), while the alternative hypothesis contains a strict inequality (<, >, or ≠). The type of inequality in the alternative hypothesis is based on the question of interest. Alternative hypotheses with < or > are called one-sided, and alternative hypotheses with ≠ are called two-sided. Although the null hypothesis for a one-sided test may include an inequality symbol, it is still tested at the boundary of equality.","tags":[]},{"id":356509,"external_key":"19.apst.0.2.5.3.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.3.2","label":"VAR-6.D.3","description":"VAR-6.D.3: The null hypothesis for a population proportion is H₀ is p = p₀, where p₀ is the null hypothesized value for the population proportion.","tags":[]},{"id":356510,"external_key":"19.apst.0.2.5.3.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.3.3","label":"VAR-6.D.4","description":"VAR-6.D.4: A one-sided alternative hypothesis for a proportion is either H_a is p < p₀ or H_a is p > p₀. A two-sided alternate hypothesis is H_a is p ≠ p0.","tags":[]},{"id":356511,"external_key":"19.apst.0.2.5.3.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.3.4","label":"VAR-6.D.5","description":"VAR-6.D.5: For a one-sample z-test for a population proportion, the null hypothesis specifies a value for the population proportion, usually one indicating no difference or effect.","tags":[]}]},{"id":356512,"external_key":"19.apst.0.2.5.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.4","label":"VAR-6.E","description":"VAR-6.E: Identify an appropriate testing method for a population proportion.","tags":[{"id":356513,"external_key":"19.apst.0.2.5.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.4.0","label":"VAR-6.E.1","description":"VAR-6.E.1: For a single categorical variable, the appropriate testing method for a population proportion is a one-sample z-test for a population proportion.","tags":[]}]},{"id":356514,"external_key":"19.apst.0.2.5.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.5","label":"VAR-6.F","description":"VAR-6.F: Verify the conditions for making statistical inferences when testing a population proportion.","tags":[{"id":356515,"external_key":"19.apst.0.2.5.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.5.0","label":"VAR-6.F.1","description":"VAR-6.F.1: In order to make statistical inferences when testing a population proportion, we must check for independence and that the sampling distribution is approximately normal- a. To check for independence- i. Data should be collected using a random sample or a randomized experiment. ii. When sampling without replacement, check that n ≤ 10%N. b. To check that the sampling distribution of p-hat is approximately normal (shape)- i. Assuming that H₀ is true (p = p₀), verify that both the number of successes, n∙p₀, and the number of failures, n(1 - p₀) are at least 10 so that that the sample size is large enough to support an assumption of normality.","tags":[]}]},{"id":356516,"external_key":"19.apst.0.2.5.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.6","label":"VAR-6.G","description":"VAR-6.G: Calculate an appropriate test statistic and p-value for a population proportion.","tags":[{"id":356517,"external_key":"19.apst.0.2.5.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.6.0","label":"VAR-6.G.1","description":"VAR-6.G.1: The distribution of the test statistic assuming the null hypothesis is true (null distribution) can be either a randomization distribution or when a probability model is assumed to be true, a theoretical distribution (z).","tags":[]},{"id":356518,"external_key":"19.apst.0.2.5.6.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.6.1","label":"VAR-6.G.2","description":"VAR-6.G.2: When using a z-test, the standardized test statistic can be written- test statistics = (sample statistic - null value of the parameter)/(standard deviation of the statistic). This is called a z-statistic for proportions.","tags":[]},{"id":356519,"external_key":"19.apst.0.2.5.6.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.6.2","label":"VAR-6.G.3","description":"VAR-6.G.3: The test statistic for a population proportion is- z = (p-hat - p₀)/√[(p₀(1 - p₀))/n].","tags":[]},{"id":356520,"external_key":"19.apst.0.2.5.6.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.6.3","label":"VAR-6.G.4","description":"VAR-6.G.4: A p-value is the probability of obtaining a test statistic as extreme or more extreme than the observed test statistic when the null hypothesis and probability model are assumed to be true. The significance level may be given or determined by the researcher.","tags":[]}]},{"id":356521,"external_key":"19.apst.0.2.5.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.7","label":"VAR-6.H","description":"VAR-6.H: Identify the null and alternative hypotheses for a difference of two population proportions.","tags":[{"id":356522,"external_key":"19.apst.0.2.5.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.7.0","label":"VAR-6.H.1","description":"VAR-6.H.1: For a two-sample test for a difference of two proportions, the null hypothesis specifies a value of 0 for the difference in population proportions, indicating no difference or effect.","tags":[]},{"id":356523,"external_key":"19.apst.0.2.5.7.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.7.1","label":"VAR-6.H.2","description":"VAR-6.H.2: The null hypothesis for a difference in proportions is- H₀ is p₁ = p₂, or H₀ is p₁ - p₂ = 0.","tags":[]},{"id":356524,"external_key":"19.apst.0.2.5.7.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.7.2","label":"VAR-6.H.3","description":"VAR-6.H.3: A one-sided alternative hypothesis for a difference in proportions is- H_a is p₁ < p₂, or, H_a is p₁ > p₂. A two-sided alternative hypothesis for a difference of proportions is H_a is p₁ ≠ p₂.","tags":[]}]},{"id":356525,"external_key":"19.apst.0.2.5.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.8","label":"VAR-6.I","description":"VAR-6.I: Identify an appropriate testing method for the difference of two population proportions.","tags":[{"id":356526,"external_key":"19.apst.0.2.5.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.8.0","label":"VAR-6.I.1","description":"VAR-6.I.1: For a single categorical variable, the appropriate testing method for the difference of two population proportions is a two-sample z-test for a difference between two population proportions.","tags":[]}]},{"id":356527,"external_key":"19.apst.0.2.5.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.9","label":"VAR-6.J","description":"VAR-6.J: Verify the conditions for making statistical inferences when testing a difference of two population proportions.","tags":[{"id":356528,"external_key":"19.apst.0.2.5.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.9.0","label":"VAR-6.J.1","description":"VAR-6.J.1: In order to make statistical inferences when testing a difference between population proportions, we must check for independence and that the sampling distribution is approximately normal- a. To check for independence- i. Data should be collected using random samples or a randomized experiment. ii. When sampling without replacement, check that n₁ ≤ 10%N₁ and n₂ ≤ 10%N₂.  b. To check that the sampling distribution of p-hat₁ - p-hat₂ is approximately normal (shape)- i. For the combined sample, define the combined (or pooled) proportion, p-hat_c = (n₁ · p-hat₁ + n2 · p-hat2)/(n₁ + n2). Assuming that H₀ is true (p₁ - p₂ = 0 or p₁ = p₂), check that n₁ · p-hat_c, n₁(1 - p-hat_c), n2 · p-hat_c, and n2(1 - p-hat_c) are all greater than or equal to some predetermined value, typically either 5 or 10.","tags":[]}]},{"id":356529,"external_key":"19.apst.0.2.5.10","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.10","label":"VAR-6.K","description":"VAR-6.K: Calculate an appropriate test statistic for the difference of two population proportions.","tags":[{"id":356530,"external_key":"19.apst.0.2.5.10.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.5.10.0","label":"VAR-6.K.1","description":"VAR-6.K.1: The test statistic for a difference in proportions is- z = [(p-hat₁ - p-hat₂) - 0]/[[√((p-hat_c)(1 - p-hat_c))]∙[√((1/n₁) + (1/n₂))]], where p-hat_c = (n₁ · p-hat₁ + n₂ · p-hat₂)/(n₁ + n2).","tags":[]}]}]},{"id":356531,"external_key":"19.apst.0.2.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6","label":"VAR-7","description":"VAR-7: The t-distribution may be used to model variation.","tags":[{"id":356532,"external_key":"19.apst.0.2.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.0","label":"VAR-7.A","description":"VAR-7.A: Describe t-distributions.","tags":[{"id":356533,"external_key":"19.apst.0.2.6.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.0.0","label":"VAR-7.A.1","description":"VAR-7.A.1: When s is used instead of sigma to calculate a test statistic, the corresponding distribution, known as the t-distribution, varies from the normal distribution in shape, in that more of the area is allocated to the tails of the density curve than in a normal distribution.","tags":[]},{"id":356534,"external_key":"19.apst.0.2.6.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.0.1","label":"VAR-7.A.2","description":"VAR-7.A.2: As the degrees of freedom increase, the area in the tails of a t-distribution decreases.","tags":[]}]},{"id":356535,"external_key":"19.apst.0.2.6.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.1","label":"VAR-7.B","description":"VAR-7.B: Identify an appropriate testing method for a population mean with unknown sigma, including the mean difference between values in matched pairs.","tags":[{"id":356536,"external_key":"19.apst.0.2.6.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.1.0","label":"VAR-7.B.1","description":"VAR-7.B.1: The appropriate test for a population mean with unknown sigma is a one-sample t-test for a population mean.","tags":[]},{"id":356537,"external_key":"19.apst.0.2.6.1.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.1.1","label":"VAR-7.B.2","description":"VAR-7.B.2: Matched pairs can be thought of as one sample of pairs. Once differences between pairs of values are found, inference for significance testing proceeds as for a population mean.","tags":[]}]},{"id":356538,"external_key":"19.apst.0.2.6.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.2","label":"VAR-7.C","description":"VAR-7.C: Identify the null and alternative hypotheses for a population mean with unknown sigma, including the mean difference between values in matched pairs.","tags":[{"id":356539,"external_key":"19.apst.0.2.6.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.2.0","label":"VAR-7.C.1","description":"VAR-7.C.1: The null hypothesis for a one-sample t-test for a population mean is H₀ is μ = μ₀, where μ₀ is the hypothesized value. Depending upon the situation, the alternative hypothesis is H_a is µ < μ₀, or H_a is µ > μ₀, or H_a is µ ≠ μ₀.","tags":[]},{"id":356540,"external_key":"19.apst.0.2.6.2.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.2.1","label":"VAR-7.C.2","description":"VAR-7.C.2: When finding the mean difference, µ_d, between values in a matched pair, it is important to define the order of subtraction.","tags":[]}]},{"id":356541,"external_key":"19.apst.0.2.6.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.3","label":"VAR-7.D","description":"VAR-7.D: Verify the conditions for the test for a population mean, including the mean difference between values in matched pairs.","tags":[{"id":356542,"external_key":"19.apst.0.2.6.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.3.0","label":"VAR-7.D.1","description":"VAR-7.D.1: In order to make statistical inferences when testing a population mean, we must check for independence and that the sampling distribution is approximately normal- a. To check for independence- i. Data should be collected using a random sample or a randomized experiment. ii. When sampling without replacement, check that n ≤ 10%N. b. To check that the sampling distribution of x-bar is approximately normal (shape)- i. If the observed distribution is skewed, n should be greater than 30. ii. If the sample size is less than 30, the distribution of the sample data should be free from strong skewness and outliers.","tags":[]}]},{"id":356543,"external_key":"19.apst.0.2.6.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.4","label":"VAR-7.E","description":"VAR-7.E: Calculate an appropriate test statistic for a population mean, including the mean difference between values in matched pairs.","tags":[{"id":356544,"external_key":"19.apst.0.2.6.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.4.0","label":"VAR-7.E.1","description":"VAR-7.E.1: For a single quantitative variable when random sampling with replacement from a population that can be modeled with a normal distribution with mean µ and standard deviation sigma, the sampling distribution of t = (x-bar  - µ)/(s/√n) has a t-distribution with n - 1 degrees of freedom.","tags":[]}]},{"id":356545,"external_key":"19.apst.0.2.6.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.5","label":"VAR-7.F","description":"VAR-7.F: Identify an appropriate selection of a testing method for a difference of two population means.","tags":[{"id":356546,"external_key":"19.apst.0.2.6.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.5.0","label":"VAR-7.F.1","description":"VAR-7.F.1: For a quantitative variable, the appropriate test for a difference of two population means is a two-sample t-test for a difference of two population means.","tags":[]}]},{"id":356547,"external_key":"19.apst.0.2.6.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.6","label":"VAR-7.G","description":"VAR-7.G: Identify the null and alternative hypotheses for a difference of two population means.","tags":[{"id":356548,"external_key":"19.apst.0.2.6.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.6.0","label":"VAR-7.G.1","description":"VAR-7.G.1: The null hypothesis for a two-sample t-test for a difference of two population means, μ₁ and μ₂, is H₀ is μ₁ - µ₂ = 0, or H₀ is μ₁ = µ₂. The alternative hypothesis is H_a is μ₁ - µ₂ < 0, or H_a is μ₁ - µ₂ > 0, or H_a is μ₁ - µ₂ ≠ 0, or H_a is μ₁ > µ₂, or H_a is μ₁ < µ₂, or H_a is μ₁ ≠ µ₂.","tags":[]}]},{"id":356549,"external_key":"19.apst.0.2.6.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.7","label":"VAR-7.H","description":"VAR-7.H: Verify the conditions for the significance test for the difference of two population means.","tags":[{"id":356550,"external_key":"19.apst.0.2.6.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.7.0","label":"VAR-7.H.1","description":"VAR-7.H.1: In order to make statistical inferences when testing a difference between population means, we must check for independence and that the sampling distribution is approximately normal- a. Individual observations should be independent- i. Data should be collected using simple random samples or a randomized experiment. ii. When sampling without replacement, check that n₁ ≤ 10%N₁ and n₂ ≤ 10%N₂. b. The sampling distribution of x-bar₁ - x-bar₂ should be approximately normal (shape). i. If the observed distribution is skewed, both n₁ and n₂ should be greater than 30. ii. If the sample size is less than 30, the distribution of the sample data should be free from strong skewness and outliers. This should be checked for BOTH samples.","tags":[]}]},{"id":356551,"external_key":"19.apst.0.2.6.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.8","label":"VAR-7.I","description":"VAR-7.I: Calculate an appropriate test statistic for a difference of two means.","tags":[{"id":356552,"external_key":"19.apst.0.2.6.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.8.0","label":"VAR-7.I.1","description":"VAR-7.I.1: For a single quantitative variable, data collected using independent random samples or a randomized experiment from two populations, each of which can be modeled with a normal distribution, the sampling distribution of t = [(x-bar₁ - x-bar₂) - (μ₁ - µ₂)]/√[((s₁)2/n₁) + ((s₂)2/n₂)] is an approximate t-distribution with degrees of freedom that can be found using technology. The degrees of freedom fall between the smaller of n₁ - 1 and n₂ - 1 and n₁ + n₂  - 2.","tags":[]}]},{"id":356553,"external_key":"19.apst.0.2.6.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.9","label":"VAR-7.J","description":"VAR-7.J: Identify the appropriate selection of a testing method for a slope of a regression model.","tags":[{"id":356554,"external_key":"19.apst.0.2.6.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.9.0","label":"VAR-7.J.1","description":"VAR-7.J.1: The appropriate test for the slope of a regression model is a t-test for a slope.","tags":[]}]},{"id":356555,"external_key":"19.apst.0.2.6.10","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.10","label":"VAR-7.K","description":"VAR-7.K: Identify appropriate null and alternative hypotheses for a slope of a regression model.","tags":[{"id":356556,"external_key":"19.apst.0.2.6.10.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.10.0","label":"VAR-7.K.1","description":"VAR-7.K.1: The null hypothesis for a t-test for a slope is H₀ is β = β₀, where β₀ is the hypothesized value from the null hypothesis. The alternative hypothesis is H_a is β < β₀ or H_a is β > β₀, or H_a is β ≠ β₀.","tags":[]}]},{"id":356557,"external_key":"19.apst.0.2.6.11","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.11","label":"VAR-7.L","description":"VAR-7.L: Verify the conditions for the significance test for the slope of a regression model.","tags":[{"id":356558,"external_key":"19.apst.0.2.6.11.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.11.0","label":"VAR-7.L.1","description":"VAR-7.L.1: In order to make statistical inferences when testing for the slope of a regression model, we must check the following- a. The true relationship between x and y is linear. Analysis of residuals may be used to verify linearity. b. The standard deviation for y, sigma_y, does not vary with x. Analysis of residuals may be used to check for approximately equal standard deviations for all x. c. To check for independence- i. Data should be collected using a random sample or a randomized experiment. ii. When sampling without replacement, check that n ≤10%N. d. For a particular value of x, the responses (y-values) are approximately normally distributed. Analysis of graphical representations of residuals may be used to check for normality- i. If the observed distribution is skewed, n should be greater than 30. ii. If the sample size is less than 30, the distribution of the sample data should be free from strong skewness and outliers.","tags":[]}]},{"id":356559,"external_key":"19.apst.0.2.6.12","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.12","label":"VAR-7.M","description":"VAR-7.M: Calculate an appropriate test statistic for the slope of a regression model.","tags":[{"id":356560,"external_key":"19.apst.0.2.6.12.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.12.0","label":"VAR-7.M.1","description":"VAR-7.M.1: The distribution of the slope of a regression model assuming all conditions are satisfied and the null hypothesis is true (null distribution) is a t-distribution.","tags":[]},{"id":356561,"external_key":"19.apst.0.2.6.12.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.6.12.1","label":"VAR-7.M.2","description":"VAR-7.M.2: For simple linear regression when random sampling from a population for the response that can be modeled with a normal distribution for each value of the explanatory variable, the sampling distribution of t = (b - β)/(SE_b) has a t-distribution with degrees of freedom equal to n - 2. When testing the slope in a simple linear regression model with one parameter, the slope, the test for the slope has df = n-1.","tags":[]}]}]},{"id":356562,"external_key":"19.apst.0.2.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7","label":"VAR-8","description":"VAR-8: The chi-square distribution may be used to model variation.","tags":[{"id":356563,"external_key":"19.apst.0.2.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.0","label":"VAR-8.A","description":"VAR-8.A: Describe chi-square distributions.","tags":[{"id":356564,"external_key":"19.apst.0.2.7.0.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.0.0","label":"VAR-8.A.1","description":"VAR-8.A.1: Expected counts of categorical data are counts consistent with the null hypothesis. In general, an expected count is a sample size times a probability.","tags":[]},{"id":356565,"external_key":"19.apst.0.2.7.0.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.0.1","label":"VAR-8.A.2","description":"VAR-8.A.2: The chi-square statistic measures the distance between observed and expected counts relative to expected counts.","tags":[]},{"id":356566,"external_key":"19.apst.0.2.7.0.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.0.2","label":"VAR-8.A.3","description":"VAR-8.A.3: Chi-square distributions have positive values and are skewed right. Within a family of density curves, the skew becomes less pronounced with increasing degrees of freedom.","tags":[]}]},{"id":356567,"external_key":"19.apst.0.2.7.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.1","label":"VAR-8.B","description":"VAR-8.B: Identify the null and alternative hypotheses in a test for a distribution of proportions in a set of categorical data.","tags":[{"id":356568,"external_key":"19.apst.0.2.7.1.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.1.0","label":"VAR-8.B.1","description":"VAR-8.B.1: For a chi-square goodness-of-fit test, the null hypothesis specifies null proportions for each category, and the alternative hypothesis is that at least one of these proportions is not as specified in the null hypothesis.","tags":[]}]},{"id":356569,"external_key":"19.apst.0.2.7.2","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.2","label":"VAR-8.C","description":"VAR-8.C: Identify an appropriate testing method for a distribution of proportions in a set of categorical data.","tags":[{"id":356570,"external_key":"19.apst.0.2.7.2.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.2.0","label":"VAR-8.C.1","description":"VAR-8.C.1: When considering a distribution of proportions for one categorical variable, the appropriate test is the chi-square test for goodness of fit.","tags":[]}]},{"id":356571,"external_key":"19.apst.0.2.7.3","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.3","label":"VAR-8.D","description":"VAR-8.D: Calculate expected counts for the chi-square test for goodness of fit.","tags":[{"id":356572,"external_key":"19.apst.0.2.7.3.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.3.0","label":"VAR-8.D.1","description":"VAR-8.D.1: Expected counts for a chi-square test for goodness-of-fit are (sample size)(null proportion).","tags":[]}]},{"id":356573,"external_key":"19.apst.0.2.7.4","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.4","label":"VAR-8.E","description":"VAR-8.E: Verify the conditions for making statistical inferences when testing goodness of fit for a chi-square distribution.","tags":[{"id":356574,"external_key":"19.apst.0.2.7.4.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.4.0","label":"VAR-8.E.1","description":"VAR-8.E.1: In order to make statistical inferences for a chi-square test for goodness of fit we must check the following-  a. To check for independence-  i. Data should be collected using a random sample or randomized experiment.  ii. When sampling without replacement, check that n≤10%N.  b. The chi-square test for goodness of fit becomes more accurate with more observations, so large counts should be used (shape)- i. A conservative check for large counts is that all expected counts should be greater than 5.","tags":[]}]},{"id":356575,"external_key":"19.apst.0.2.7.5","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.5","label":"VAR-8.F","description":"VAR-8.F: Calculate the appropriate statistic for the chi-square test for goodness of fit.","tags":[{"id":356576,"external_key":"19.apst.0.2.7.5.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.5.0","label":"VAR-8.F.1","description":"VAR-8.F.1: The test statistic for the chi-square test for goodness of fit is χ2 = ∑[(Observed count - Expected count)²/(Expected count)], with degrees of freedom = number of categories - 1.","tags":[]},{"id":356577,"external_key":"19.apst.0.2.7.5.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.5.1","label":"VAR-8.F.2","description":"VAR-8.F.2: The distribution of the test statistic assuming the null hypothesis is true (null distribution) can be either a randomization distribution or, when a probability model is assumed to be true, a theoretical distribution (chi-square).","tags":[]}]},{"id":356578,"external_key":"19.apst.0.2.7.6","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.6","label":"VAR-8.G","description":"VAR-8.G: Determine the p-value for chi-square test for goodness of fit significance test.","tags":[{"id":356579,"external_key":"19.apst.0.2.7.6.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.6.0","label":"VAR-8.G.1","description":"VAR-8.G.1: The p-value for a chi-square test for goodness of fit for a number of degrees of freedom is found using the appropriate table or computer generated output.","tags":[]}]},{"id":356580,"external_key":"19.apst.0.2.7.7","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.7","label":"VAR-8.H","description":"VAR-8.H: Calculate expected counts for two-way tables of categorical data.","tags":[{"id":356581,"external_key":"19.apst.0.2.7.7.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.7.0","label":"VAR-8.H.1","description":"VAR-8.H.1: The expected count in a particular cell of a two-way table of categorical data can be calculated using the formula- expected count = [(row total)(column total)]/(table total).","tags":[]}]},{"id":356582,"external_key":"19.apst.0.2.7.8","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.8","label":"VAR-8.I","description":"VAR-8.I: Identify the null and alternative hypotheses for a chi-square test for homogeneity or independence.","tags":[{"id":356583,"external_key":"19.apst.0.2.7.8.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.8.0","label":"VAR-8.I.1","description":"VAR-8.I.1: The appropriate hypotheses for a chi-square test for homogeneity are- H₀ - There is no difference in distributions of a categorical variable across populations or treatments. H_a - There is a difference in distributions of a categorical variable across populations or treatments.","tags":[]},{"id":356584,"external_key":"19.apst.0.2.7.8.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.8.1","label":"VAR-8.I.2","description":"VAR-8.I.2: The appropriate hypotheses for a chi-square test for independence are- H₀ - There is no association between two categorical variables in a given population or the two categorical variables are independent.  H_a - Two categorical variables in a population are associated or dependent.","tags":[]}]},{"id":356585,"external_key":"19.apst.0.2.7.9","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.9","label":"VAR-8.J","description":"VAR-8.J: Identify an appropriate testing method for comparing distributions in two-way tables of categorical data.","tags":[{"id":356586,"external_key":"19.apst.0.2.7.9.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.9.0","label":"VAR-8.J.1","description":"VAR-8.J.1: When comparing distributions to determine whether proportions in each category for categorical data collected from different populations are the same, the appropriate test is the chi-square test for homogeneity.","tags":[]},{"id":356587,"external_key":"19.apst.0.2.7.9.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.9.1","label":"VAR-8.J.2","description":"VAR-8.J.2: To determine whether row and column variables in a two-way table of categorical data might be associated in the population from which the data were sampled, the appropriate test is the chi-square test for independence.","tags":[]}]},{"id":356588,"external_key":"19.apst.0.2.7.10","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.10","label":"VAR-8.K","description":"VAR-8.K: Verify the conditions for making statistical inferences when testing a chi-square distribution for independence or homogeneity.","tags":[{"id":356589,"external_key":"19.apst.0.2.7.10.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.10.0","label":"VAR-8.K.1","description":"VAR-8.K.1: In order to make statistical inferences for a chi-square test for two-way tables (homogeneity or independence), we must verify the following- a. To check for independence- i. For a test for independence; Data should be collected using a simple random sample. ii. For a test for homogeneity; Data should be collected using a stratified random sample or randomized experiment. iii. When sampling without replacement, check that n ≤ 10%N. b. The chi-square tests for independence and homogeneity become more accurate with more observations, so large counts should be used (shape). i. A conservative check for large counts is that all expected counts should be greater than 5.","tags":[]},{"id":356590,"external_key":"19.apst.0.2.7.10.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.10.1","label":"VAR-8.L.1","description":"VAR-8.L.1: The appropriate test statistic for a chi-square test for homogeneity or independence is the chi-square statistic χ2 = ∑[(Observed count - Expected count)²/(Expected count)], with degrees of freedom equal to (number of rows - 1)(number of columns - 1).","tags":[]}]},{"id":356591,"external_key":"19.apst.0.2.7.11","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.11","label":"VAR-8.L","description":"VAR-8.L: Calculate the appropriate statistic for a chi-square test for homogeneity or independence.","tags":[{"id":356592,"external_key":"19.apst.0.2.7.11.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.11.0","label":"VAR-8.L.1","description":"VAR-8.L.1: The appropriate test statistic for a chi-square test for homogeneity or independence is the chi-square statistic χ2 = ∑[(Observed count - Expected count)²/(Expected count)], with degrees of freedom equal to (number of rows - 1)(number of columns - 1).","tags":[]},{"id":356593,"external_key":"19.apst.0.2.7.11.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.11.1","label":"VAR-8.K.1","description":"VAR-8.K.1: In order to make statistical inferences for a chi-square test for two-way tables (homogeneity or independence), we must verify the following- a. To check for independence- i. For a test for independence; Data should be collected using a simple random sample. ii. For a test for homogeneity; Data should be collected using a stratified random sample or randomized experiment. iii. When sampling without replacement, check that n ≤ 10%N. b. The chi-square tests for independence and homogeneity become more accurate with more observations, so large counts should be used (shape). i. A conservative check for large counts is that all expected counts should be greater than 5.","tags":[]}]},{"id":356594,"external_key":"19.apst.0.2.7.12","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.12","label":"VAR-8.M","description":"VAR-8.M: Determine the p-value for a chi-square significance test for independence or homogeneity.","tags":[{"id":356595,"external_key":"19.apst.0.2.7.12.0","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.12.0","label":"VAR-8.M.1","description":"VAR-8.M.1: The p-value for a chi-square test for independence or homogeneity for a number of degrees of freedom is found using the appropriate table or technology.","tags":[]},{"id":356596,"external_key":"19.apst.0.2.7.12.1","internal_name":"2019-AP-Statistics-Framework-19.apst.0.2.7.12.1","label":"VAR-8.M.2","description":"VAR-8.M.2: For a test of independence or homogeneity for a two-way table, the p-value is the proportion of values in a chi-square distribution with appropriate degrees of freedom that are equal to or larger than the test statistic.","tags":[]}]}]}]}]}]},{"id":22739,"internal_name":"2019-AP-Statistics-Subject-Stimulus-Type","label":"Stimulus Type","description":"Stimulus Type","tags":[{"id":356760,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Stimulus-Type-Graph","label":"Graph","description":"Graph","tags":[]},{"id":356761,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Stimulus-Type-Plot","label":"Plot","description":"Plot","tags":[]},{"id":356762,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Stimulus-Type-Table","label":"Table","description":"Table","tags":[]},{"id":356763,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Stimulus-Type-Computer-output","label":"Computer output","description":"Computer output","tags":[]},{"id":356764,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Stimulus-Type-Diagram","label":"Diagram","description":"Diagram","tags":[]},{"id":356765,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Stimulus-Type-Data-Set","label":"Data Set","description":"Data Set","tags":[]},{"id":356766,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Stimulus-Type-No-stimulus","label":"No stimulus","description":"No stimulus","tags":[]}]},{"id":22737,"internal_name":"2019-AP-Statistics-Subject-Question-Type","label":"Question Type","description":"Question Type","tags":[{"id":356755,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Question-Type-MCQ","label":"MCQ","description":"MCQ","tags":[]},{"id":356756,"external_key":null,"internal_name":"2019-AP-Statistics-Subject-Question-Type-FRQ","label":"FRQ","description":"FRQ","tags":[]}]},{"id":22741,"internal_name":"2019-AP-Statistics-General-Security","label":"Security","description":"Security","tags":[{"id":356773,"external_key":null,"internal_name":"2019-AP-Statistics-General-Security-Teacher-Use-Only","label":"Teacher Use Only","description":"Teacher Use Only","tags":[]},{"id":356774,"external_key":null,"internal_name":"2019-AP-Statistics-General-Security-Publicly-Available","label":"Publicly Available","description":"Publicly Available","tags":[]}]}],"below_fold":[]}